{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-on: Training and deploying GluonNLP models on AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "You will learn the following:\n",
    "\n",
    "- practice fine-tuning BERT for sentiment classification\n",
    "- exporting models in a self-contained way\n",
    "- creating a SageMaker Endpoint serving your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras-mxnet                        2.2.4.2       \n",
      "mxnet-cu101                        1.6.0b20191122\n",
      "mxnet-model-server                 1.0.5         \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "gluonnlp                           0.9.0.dev0    \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# this notebook requires mxnet-cu101 >= 1.6.0b20191102, gluonnlp >= 0.9.0\n",
    "# you can create a sagemaker notebook instance with the lifecycle configuration file: sagemaker-lifecycle.config\n",
    "!pip list | grep mxnet\n",
    "!pip list | grep gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import argparse, time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "lr = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Get Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can load the pre-trained BERT easily using the model API in GluonNLP, which returns the vocabulary along with the model. We include the pooler layer of the pre-trained model by setting `use_pooler` to `True`.\n",
    "The list of pre-trained BERT models available in GluonNLP can be found [here](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:54.906532Z",
     "start_time": "2019-07-26T22:44:34.102308Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab file is not found. Downloading.\n",
      "Downloading /home/ec2-user/SageMaker/models/1574881370.8280566book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n",
      "Downloading /home/ec2-user/SageMaker/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n"
     ]
    }
   ],
   "source": [
    "ctx = mx.gpu(0)\n",
    "bert, vocabulary = nlp.model.get_model('bert_12_768_12', # the 12-layer BERT Base model\n",
    "                                            dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                            # use pre-trained weights\n",
    "                                            pretrained=True, ctx=ctx,\n",
    "                                            # decoder and classifier are for pre-training only\n",
    "                                            use_decoder=False, use_classifier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now that we have loaded the BERT model, we only need to attach an additional layer for classification.\n",
    "The `BERTClassifier` class uses a BERT base model to encode sentence representation, followed by a `nn.Dense` layer for classification. We only need to initialize the classification layer. The encoding layers are already initialized with pre-trained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "net = nlp.model.BERTClassifier(bert, num_classes=2)\n",
    "net.classifier.initialize(ctx=ctx)  # only initialize the classification layer from scratch\n",
    "net.hybridize()  # compile the model, required for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To use the pre-trained BERT model, we need to:\n",
    "- tokenize the inputs into words,\n",
    "- insert [CLS] at the beginning of a sentence, \n",
    "- insert [SEP] at the end of a sentence, and\n",
    "- generate segment ids\n",
    "\n",
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We again use the IMDB dataset, but for this time, downloading using the GluonNLP data API. We then use the transform API to transform the raw scores to positive labels and negative labels. \n",
    "To process sentences with BERT-style '[CLS]', '[SEP]' tokens, you can use `data.BERTSentenceTransform` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.188028Z",
     "start_time": "2019-07-26T22:44:57.181395Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/SageMaker/datasets/imdb/train.json from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/imdb/train.json...\n",
      "Downloading /home/ec2-user/SageMaker/datasets/imdb/test.json from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/imdb/test.json...\n"
     ]
    }
   ],
   "source": [
    "train_dataset_raw = nlp.data.IMDB('train')\n",
    "test_dataset_raw = nlp.data.IMDB('test')\n",
    "# tokenize texts into words\n",
    "tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
    "# add begin-of-sentence, end-of-sentence tokens and perform vocabulary lookup\n",
    "transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=128, pair=False)\n",
    "\n",
    "def transform_fn(data):\n",
    "    # transform texts to tensors\n",
    "    text, label = data\n",
    "    # transform label into position / negative\n",
    "    label = 1 if label >= 5 else 0\n",
    "    data, length, segment_type = transform([text])\n",
    "    return data.astype('float32'), length.astype('float32'), segment_type.astype('float32'), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.197310Z",
     "start_time": "2019-07-26T22:44:57.189448Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence = \n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n",
      "\n",
      "word indices = \n",
      "[    2 22953  2213  4381  2152  2003  1037  9476  4038  1012  2009  2743\n",
      "  2012  1996  2168  2051  2004  2070  2060  3454  2055  2082  2166  1010\n",
      "  2107  2004  1000  5089  1000  1012  2026  3486  2086  1999  1996  4252\n",
      "  9518  2599  2033  2000  2903  2008 22953  2213  4381  2152  1005  1055\n",
      " 18312  2003  2172  3553  2000  4507  2084  2003  1000  5089  1000  1012\n",
      "  1996 25740  2000  5788 13732  1010  1996 12369  3993  2493  2040  2064\n",
      "  2156  2157  2083  2037 17203  5089  1005 13433  8737  1010  1996  9004\n",
      " 10196  4757  1997  1996  2878  3663  1010  2035 10825  2033  1997  1996\n",
      "  2816  1045  2354  1998  2037  2493  1012  2043  1045  2387  1996  2792\n",
      "  1999  2029  1037  3076  8385  2699  2000  6402  2091  1996  2082  1010\n",
      "  1045  3202  7383  1012  1012  1012  1012     3]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset_raw.transform(transform_fn)\n",
    "test_dataset = test_dataset_raw.transform(transform_fn)\n",
    "\n",
    "data, length, _, label = train_dataset[0]\n",
    "print('original sentence = \\n{}'.format(train_dataset_raw[0][0]))\n",
    "print('\\nword indices = \\n{}'.format(data.astype('int32')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we have all the pieces to put together, and we can finally start fine-tuning the\n",
    "model with a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "padding_id = vocabulary[vocabulary.padding_token]\n",
    "batchify_fn = nlp.data.batchify.Tuple(\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=padding_id), # words\n",
    "        nlp.data.batchify.Stack(), # valid length\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=0), # segment type\n",
    "        nlp.data.batchify.Stack(np.float32)) # label\n",
    "\n",
    "train_data = mx.gluon.data.DataLoader(train_dataset,\n",
    "                               batchify_fn=batchify_fn, shuffle=True,\n",
    "                               batch_size=batch_size, num_workers=4)\n",
    "test_data = mx.gluon.data.DataLoader(test_dataset,\n",
    "                              batchify_fn=batchify_fn,\n",
    "                              shuffle=False, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.contrib.estimator import TrainBegin, BatchBegin, LoggingHandler\n",
    "\n",
    "\n",
    "class MyLearningRateHandler(TrainBegin, BatchBegin):\n",
    "    \"\"\"Warm-up learning rate handler.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trainer: gluon.Trainer\n",
    "        Trainer object to adjust the learning rate on.\n",
    "    num_warmup_steps: int\n",
    "        Number of initial steps during which the learning rate is linearly\n",
    "        increased to it's target.\n",
    "    num_train_steps: int\n",
    "        Total number of steps to be taken during training. Should be equal to\n",
    "        the number of batches * number of epochs.\n",
    "    lr: float\n",
    "        Base learning rate to reach after warmup.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, trainer, num_warmup_steps, num_train_steps, lr):\n",
    "        self.trainer = trainer\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.lr = lr\n",
    "\n",
    "        self.step_num = 0\n",
    "\n",
    "    def train_begin(self, estimator, *args, **kwargs):\n",
    "        self.step_num = 0\n",
    "\n",
    "    def batch_begin(self, estimator, *args, **kwargs):\n",
    "        self.step_num += 1\n",
    "        if self.step_num < self.num_warmup_steps:\n",
    "            new_lr = self.lr * self.step_num / self.num_warmup_steps\n",
    "        else:\n",
    "            non_warmup_steps = self.step_num - self.num_warmup_steps\n",
    "            offset = non_warmup_steps / (self.num_train_steps - self.num_warmup_steps)\n",
    "            new_lr = self.lr - offset * self.lr\n",
    "        self.trainer.set_learning_rate(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.contrib import estimator\n",
    "from mxnet.gluon.utils import split_and_load\n",
    "\n",
    "class MyEstimator(estimator.Estimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # params for grad clipping\n",
    "        self.params = [p for p in self.net.collect_params().values() if p.grad_req != 'null']\n",
    "        \n",
    "    def fit_batch(self, train_batch, batch_axis=0):\n",
    "        train_batch = [split_and_load(x, ctx_list=self.context, batch_axis=batch_axis) for x in train_batch]\n",
    "        with mx.autograd.record():\n",
    "            pred = [self.net(inp, token_type, seq_len) for inp, seq_len, token_type, _ in zip(*train_batch)]\n",
    "            loss = [self.loss(out, label.astype('float32')) for out, _, _, _, label in zip(pred, *train_batch)]\n",
    "        mx.autograd.backward(loss)\n",
    "\n",
    "        # Gradient clipping\n",
    "        trainer.allreduce_grads()\n",
    "        nlp.utils.clip_grad_global_norm(self.params, 1)\n",
    "        trainer.update(1)\n",
    "        \n",
    "        return train_batch[:3], train_batch[3], pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begin: using optimizer BERTAdam with current learning rate 0.0001 \n",
      "Train for 1 epochs.\n",
      "[Epoch 0] Begin, current learning rate: 0.0001\n",
      "[Epoch 0][Batch 0][Samples 32] time/batch: 6.707s training loss: 0.6562, training accuracy: 0.6562\n",
      "[Epoch 0][Batch 1][Samples 64] time/batch: 0.267s training loss: 0.7243, training accuracy: 0.5469\n",
      "[Epoch 0][Batch 2][Samples 96] time/batch: 0.260s training loss: 0.7184, training accuracy: 0.5625\n",
      "[Epoch 0][Batch 3][Samples 128] time/batch: 0.258s training loss: 0.7118, training accuracy: 0.5703\n",
      "[Epoch 0][Batch 4][Samples 160] time/batch: 0.262s training loss: 0.7197, training accuracy: 0.5375\n",
      "[Epoch 0][Batch 5][Samples 192] time/batch: 0.261s training loss: 0.7114, training accuracy: 0.5469\n",
      "[Epoch 0][Batch 6][Samples 224] time/batch: 0.255s training loss: 0.7151, training accuracy: 0.5312\n",
      "[Epoch 0][Batch 7][Samples 256] time/batch: 0.270s training loss: 0.7277, training accuracy: 0.5117\n",
      "[Epoch 0][Batch 8][Samples 288] time/batch: 0.265s training loss: 0.7240, training accuracy: 0.5139\n",
      "[Epoch 0][Batch 9][Samples 320] time/batch: 0.259s training loss: 0.7192, training accuracy: 0.5188\n",
      "[Epoch 0][Batch 10][Samples 352] time/batch: 0.255s training loss: 0.7186, training accuracy: 0.5170\n",
      "[Epoch 0][Batch 11][Samples 384] time/batch: 0.260s training loss: 0.7171, training accuracy: 0.5234\n",
      "[Epoch 0][Batch 12][Samples 416] time/batch: 0.256s training loss: 0.7127, training accuracy: 0.5312\n",
      "[Epoch 0][Batch 13][Samples 448] time/batch: 0.260s training loss: 0.7125, training accuracy: 0.5223\n",
      "[Epoch 0][Batch 14][Samples 480] time/batch: 0.255s training loss: 0.7067, training accuracy: 0.5354\n",
      "[Epoch 0][Batch 15][Samples 512] time/batch: 0.262s training loss: 0.7010, training accuracy: 0.5449\n",
      "[Epoch 0][Batch 16][Samples 544] time/batch: 0.261s training loss: 0.6956, training accuracy: 0.5551\n",
      "[Epoch 0][Batch 17][Samples 576] time/batch: 0.259s training loss: 0.6910, training accuracy: 0.5642\n",
      "[Epoch 0][Batch 18][Samples 608] time/batch: 0.266s training loss: 0.6852, training accuracy: 0.5707\n",
      "[Epoch 0][Batch 19][Samples 640] time/batch: 0.271s training loss: 0.6822, training accuracy: 0.5703\n",
      "[Epoch 0][Batch 20][Samples 672] time/batch: 0.267s training loss: 0.6692, training accuracy: 0.5833\n",
      "[Epoch 0][Batch 21][Samples 704] time/batch: 0.265s training loss: 0.6570, training accuracy: 0.5952\n",
      "[Epoch 0][Batch 22][Samples 736] time/batch: 0.265s training loss: 0.6409, training accuracy: 0.6073\n",
      "[Epoch 0][Batch 23][Samples 768] time/batch: 0.262s training loss: 0.6255, training accuracy: 0.6172\n",
      "[Epoch 0][Batch 24][Samples 800] time/batch: 0.262s training loss: 0.6192, training accuracy: 0.6250\n",
      "[Epoch 0][Batch 25][Samples 832] time/batch: 0.258s training loss: 0.6242, training accuracy: 0.6298\n",
      "[Epoch 0][Batch 26][Samples 864] time/batch: 0.259s training loss: 0.6155, training accuracy: 0.6366\n",
      "[Epoch 0][Batch 27][Samples 896] time/batch: 0.256s training loss: 0.6163, training accuracy: 0.6417\n",
      "[Epoch 0][Batch 28][Samples 928] time/batch: 0.261s training loss: 0.6099, training accuracy: 0.6476\n",
      "[Epoch 0][Batch 29][Samples 960] time/batch: 0.260s training loss: 0.6023, training accuracy: 0.6521\n",
      "[Epoch 0][Batch 30][Samples 992] time/batch: 0.268s training loss: 0.5975, training accuracy: 0.6603\n",
      "[Epoch 0][Batch 31][Samples 1024] time/batch: 0.270s training loss: 0.6039, training accuracy: 0.6572\n",
      "[Epoch 0][Batch 32][Samples 1056] time/batch: 0.259s training loss: 0.6001, training accuracy: 0.6610\n",
      "[Epoch 0][Batch 33][Samples 1088] time/batch: 0.260s training loss: 0.5976, training accuracy: 0.6636\n",
      "[Epoch 0][Batch 34][Samples 1120] time/batch: 0.257s training loss: 0.5980, training accuracy: 0.6643\n",
      "[Epoch 0][Batch 35][Samples 1152] time/batch: 0.271s training loss: 0.5904, training accuracy: 0.6710\n",
      "[Epoch 0][Batch 36][Samples 1184] time/batch: 0.258s training loss: 0.5822, training accuracy: 0.6765\n",
      "[Epoch 0][Batch 37][Samples 1216] time/batch: 0.259s training loss: 0.5836, training accuracy: 0.6785\n",
      "[Epoch 0][Batch 38][Samples 1248] time/batch: 0.258s training loss: 0.5767, training accuracy: 0.6827\n",
      "[Epoch 0][Batch 39][Samples 1280] time/batch: 0.261s training loss: 0.5789, training accuracy: 0.6836\n",
      "[Epoch 0][Batch 40][Samples 1312] time/batch: 0.256s training loss: 0.5805, training accuracy: 0.6837\n",
      "[Epoch 0][Batch 41][Samples 1344] time/batch: 0.266s training loss: 0.5793, training accuracy: 0.6860\n",
      "[Epoch 0][Batch 42][Samples 1376] time/batch: 0.260s training loss: 0.5744, training accuracy: 0.6911\n",
      "[Epoch 0][Batch 43][Samples 1408] time/batch: 0.257s training loss: 0.5716, training accuracy: 0.6932\n",
      "[Epoch 0][Batch 44][Samples 1440] time/batch: 0.261s training loss: 0.5671, training accuracy: 0.6979\n",
      "[Epoch 0][Batch 45][Samples 1472] time/batch: 0.260s training loss: 0.5649, training accuracy: 0.7018\n",
      "[Epoch 0][Batch 46][Samples 1504] time/batch: 0.266s training loss: 0.5691, training accuracy: 0.7001\n",
      "[Epoch 0][Batch 47][Samples 1536] time/batch: 0.258s training loss: 0.5675, training accuracy: 0.7018\n",
      "[Epoch 0][Batch 48][Samples 1568] time/batch: 0.257s training loss: 0.5690, training accuracy: 0.7022\n",
      "[Epoch 0][Batch 49][Samples 1600] time/batch: 0.258s training loss: 0.5649, training accuracy: 0.7056\n",
      "[Epoch 0][Batch 50][Samples 1632] time/batch: 0.258s training loss: 0.5582, training accuracy: 0.7096\n",
      "[Epoch 0][Batch 51][Samples 1664] time/batch: 0.258s training loss: 0.5540, training accuracy: 0.7115\n",
      "[Epoch 0][Batch 52][Samples 1696] time/batch: 0.273s training loss: 0.5547, training accuracy: 0.7117\n",
      "[Epoch 0][Batch 53][Samples 1728] time/batch: 0.268s training loss: 0.5514, training accuracy: 0.7135\n",
      "[Epoch 0][Batch 54][Samples 1760] time/batch: 0.263s training loss: 0.5496, training accuracy: 0.7159\n",
      "[Epoch 0][Batch 55][Samples 1792] time/batch: 0.262s training loss: 0.5450, training accuracy: 0.7182\n",
      "[Epoch 0][Batch 56][Samples 1824] time/batch: 0.261s training loss: 0.5471, training accuracy: 0.7177\n",
      "[Epoch 0][Batch 57][Samples 1856] time/batch: 0.257s training loss: 0.5464, training accuracy: 0.7177\n",
      "[Epoch 0][Batch 58][Samples 1888] time/batch: 0.261s training loss: 0.5436, training accuracy: 0.7198\n",
      "[Epoch 0][Batch 59][Samples 1920] time/batch: 0.260s training loss: 0.5413, training accuracy: 0.7208\n",
      "[Epoch 0][Batch 60][Samples 1952] time/batch: 0.268s training loss: 0.5400, training accuracy: 0.7223\n",
      "[Epoch 0][Batch 61][Samples 1984] time/batch: 0.271s training loss: 0.5372, training accuracy: 0.7238\n",
      "[Epoch 0][Batch 62][Samples 2016] time/batch: 0.259s training loss: 0.5332, training accuracy: 0.7267\n",
      "[Epoch 0][Batch 63][Samples 2048] time/batch: 0.257s training loss: 0.5329, training accuracy: 0.7271\n",
      "[Epoch 0][Batch 64][Samples 2080] time/batch: 0.259s training loss: 0.5301, training accuracy: 0.7288\n",
      "[Epoch 0][Batch 65][Samples 2112] time/batch: 0.264s training loss: 0.5282, training accuracy: 0.7301\n",
      "[Epoch 0][Batch 66][Samples 2144] time/batch: 0.262s training loss: 0.5323, training accuracy: 0.7290\n",
      "[Epoch 0][Batch 67][Samples 2176] time/batch: 0.260s training loss: 0.5309, training accuracy: 0.7293\n",
      "[Epoch 0][Batch 68][Samples 2208] time/batch: 0.271s training loss: 0.5314, training accuracy: 0.7296\n",
      "[Epoch 0][Batch 69][Samples 2240] time/batch: 0.269s training loss: 0.5285, training accuracy: 0.7312\n",
      "[Epoch 0][Batch 70][Samples 2272] time/batch: 0.268s training loss: 0.5283, training accuracy: 0.7324\n",
      "[Epoch 0][Batch 71][Samples 2304] time/batch: 0.272s training loss: 0.5280, training accuracy: 0.7322\n",
      "[Epoch 0][Batch 72][Samples 2336] time/batch: 0.267s training loss: 0.5262, training accuracy: 0.7333\n",
      "[Epoch 0][Batch 73][Samples 2368] time/batch: 0.268s training loss: 0.5252, training accuracy: 0.7331\n",
      "[Epoch 0][Batch 74][Samples 2400] time/batch: 0.269s training loss: 0.5282, training accuracy: 0.7304\n",
      "[Epoch 0][Batch 75][Samples 2432] time/batch: 0.267s training loss: 0.5282, training accuracy: 0.7290\n",
      "[Epoch 0][Batch 76][Samples 2464] time/batch: 0.262s training loss: 0.5260, training accuracy: 0.7309\n",
      "[Epoch 0][Batch 77][Samples 2496] time/batch: 0.268s training loss: 0.5237, training accuracy: 0.7324\n",
      "[Epoch 0][Batch 78][Samples 2528] time/batch: 0.283s training loss: 0.5230, training accuracy: 0.7334\n",
      "[Epoch 0][Batch 79][Samples 2560] time/batch: 0.258s training loss: 0.5229, training accuracy: 0.7328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 80][Samples 2592] time/batch: 0.262s training loss: 0.5240, training accuracy: 0.7315\n",
      "[Epoch 0][Batch 81][Samples 2624] time/batch: 0.259s training loss: 0.5231, training accuracy: 0.7332\n",
      "[Epoch 0][Batch 82][Samples 2656] time/batch: 0.276s training loss: 0.5234, training accuracy: 0.7319\n",
      "[Epoch 0][Batch 83][Samples 2688] time/batch: 0.258s training loss: 0.5231, training accuracy: 0.7325\n",
      "[Epoch 0][Batch 84][Samples 2720] time/batch: 0.260s training loss: 0.5232, training accuracy: 0.7320\n",
      "[Epoch 0][Batch 85][Samples 2752] time/batch: 0.263s training loss: 0.5219, training accuracy: 0.7329\n",
      "[Epoch 0][Batch 86][Samples 2784] time/batch: 0.257s training loss: 0.5224, training accuracy: 0.7324\n",
      "[Epoch 0][Batch 87][Samples 2816] time/batch: 0.263s training loss: 0.5191, training accuracy: 0.7347\n",
      "[Epoch 0][Batch 88][Samples 2848] time/batch: 0.260s training loss: 0.5183, training accuracy: 0.7353\n",
      "[Epoch 0][Batch 89][Samples 2880] time/batch: 0.263s training loss: 0.5190, training accuracy: 0.7351\n",
      "[Epoch 0][Batch 90][Samples 2912] time/batch: 0.263s training loss: 0.5200, training accuracy: 0.7352\n",
      "[Epoch 0][Batch 91][Samples 2944] time/batch: 0.261s training loss: 0.5214, training accuracy: 0.7344\n",
      "[Epoch 0][Batch 92][Samples 2976] time/batch: 0.273s training loss: 0.5222, training accuracy: 0.7342\n",
      "[Epoch 0][Batch 93][Samples 3008] time/batch: 0.264s training loss: 0.5206, training accuracy: 0.7347\n",
      "[Epoch 0][Batch 94][Samples 3040] time/batch: 0.260s training loss: 0.5205, training accuracy: 0.7349\n",
      "[Epoch 0][Batch 95][Samples 3072] time/batch: 0.259s training loss: 0.5201, training accuracy: 0.7354\n",
      "[Epoch 0][Batch 96][Samples 3104] time/batch: 0.262s training loss: 0.5195, training accuracy: 0.7365\n",
      "[Epoch 0][Batch 97][Samples 3136] time/batch: 0.259s training loss: 0.5189, training accuracy: 0.7379\n",
      "[Epoch 0][Batch 98][Samples 3168] time/batch: 0.261s training loss: 0.5184, training accuracy: 0.7393\n",
      "[Epoch 0][Batch 99][Samples 3200] time/batch: 0.258s training loss: 0.5185, training accuracy: 0.7397\n",
      "[Epoch 0][Batch 100][Samples 3232] time/batch: 0.258s training loss: 0.5170, training accuracy: 0.7407\n",
      "[Epoch 0][Batch 101][Samples 3264] time/batch: 0.261s training loss: 0.5163, training accuracy: 0.7408\n",
      "[Epoch 0][Batch 102][Samples 3296] time/batch: 0.259s training loss: 0.5140, training accuracy: 0.7424\n",
      "[Epoch 0][Batch 103][Samples 3328] time/batch: 0.258s training loss: 0.5130, training accuracy: 0.7434\n",
      "[Epoch 0][Batch 104][Samples 3360] time/batch: 0.262s training loss: 0.5126, training accuracy: 0.7443\n",
      "[Epoch 0][Batch 105][Samples 3392] time/batch: 0.259s training loss: 0.5105, training accuracy: 0.7462\n",
      "[Epoch 0][Batch 106][Samples 3424] time/batch: 0.261s training loss: 0.5110, training accuracy: 0.7462\n",
      "[Epoch 0][Batch 107][Samples 3456] time/batch: 0.261s training loss: 0.5082, training accuracy: 0.7480\n",
      "[Epoch 0][Batch 108][Samples 3488] time/batch: 0.263s training loss: 0.5069, training accuracy: 0.7483\n",
      "[Epoch 0][Batch 109][Samples 3520] time/batch: 0.264s training loss: 0.5075, training accuracy: 0.7486\n",
      "[Epoch 0][Batch 110][Samples 3552] time/batch: 0.272s training loss: 0.5076, training accuracy: 0.7489\n",
      "[Epoch 0][Batch 111][Samples 3584] time/batch: 0.268s training loss: 0.5083, training accuracy: 0.7489\n",
      "[Epoch 0][Batch 112][Samples 3616] time/batch: 0.265s training loss: 0.5061, training accuracy: 0.7497\n",
      "[Epoch 0][Batch 113][Samples 3648] time/batch: 0.259s training loss: 0.5053, training accuracy: 0.7503\n",
      "[Epoch 0][Batch 114][Samples 3680] time/batch: 0.261s training loss: 0.5042, training accuracy: 0.7514\n",
      "[Epoch 0][Batch 115][Samples 3712] time/batch: 0.266s training loss: 0.5034, training accuracy: 0.7519\n",
      "[Epoch 0][Batch 116][Samples 3744] time/batch: 0.261s training loss: 0.5020, training accuracy: 0.7535\n",
      "[Epoch 0][Batch 117][Samples 3776] time/batch: 0.261s training loss: 0.5014, training accuracy: 0.7540\n",
      "[Epoch 0][Batch 118][Samples 3808] time/batch: 0.263s training loss: 0.5014, training accuracy: 0.7542\n",
      "[Epoch 0][Batch 119][Samples 3840] time/batch: 0.257s training loss: 0.5007, training accuracy: 0.7549\n",
      "[Epoch 0][Batch 120][Samples 3872] time/batch: 0.261s training loss: 0.5001, training accuracy: 0.7557\n",
      "[Epoch 0][Batch 121][Samples 3904] time/batch: 0.259s training loss: 0.5001, training accuracy: 0.7556\n",
      "[Epoch 0][Batch 122][Samples 3936] time/batch: 0.258s training loss: 0.4994, training accuracy: 0.7561\n",
      "[Epoch 0][Batch 123][Samples 3968] time/batch: 0.261s training loss: 0.4976, training accuracy: 0.7571\n",
      "[Epoch 0][Batch 124][Samples 4000] time/batch: 0.257s training loss: 0.4966, training accuracy: 0.7580\n",
      "[Epoch 0][Batch 125][Samples 4032] time/batch: 0.263s training loss: 0.4958, training accuracy: 0.7584\n",
      "[Epoch 0][Batch 126][Samples 4064] time/batch: 0.259s training loss: 0.4962, training accuracy: 0.7581\n",
      "[Epoch 0][Batch 127][Samples 4096] time/batch: 0.275s training loss: 0.4942, training accuracy: 0.7593\n",
      "[Epoch 0][Batch 128][Samples 4128] time/batch: 0.275s training loss: 0.4940, training accuracy: 0.7590\n",
      "[Epoch 0][Batch 129][Samples 4160] time/batch: 0.263s training loss: 0.4939, training accuracy: 0.7594\n",
      "[Epoch 0][Batch 130][Samples 4192] time/batch: 0.267s training loss: 0.4938, training accuracy: 0.7598\n",
      "[Epoch 0][Batch 131][Samples 4224] time/batch: 0.265s training loss: 0.4926, training accuracy: 0.7609\n",
      "[Epoch 0][Batch 132][Samples 4256] time/batch: 0.267s training loss: 0.4922, training accuracy: 0.7615\n",
      "[Epoch 0][Batch 133][Samples 4288] time/batch: 0.267s training loss: 0.4919, training accuracy: 0.7614\n",
      "[Epoch 0][Batch 134][Samples 4320] time/batch: 0.274s training loss: 0.4908, training accuracy: 0.7620\n",
      "[Epoch 0][Batch 135][Samples 4352] time/batch: 0.271s training loss: 0.4895, training accuracy: 0.7624\n",
      "[Epoch 0][Batch 136][Samples 4384] time/batch: 0.262s training loss: 0.4890, training accuracy: 0.7625\n",
      "[Epoch 0][Batch 137][Samples 4416] time/batch: 0.259s training loss: 0.4891, training accuracy: 0.7625\n",
      "[Epoch 0][Batch 138][Samples 4448] time/batch: 0.264s training loss: 0.4883, training accuracy: 0.7630\n",
      "[Epoch 0][Batch 139][Samples 4480] time/batch: 0.269s training loss: 0.4870, training accuracy: 0.7641\n",
      "[Epoch 0][Batch 140][Samples 4512] time/batch: 0.259s training loss: 0.4856, training accuracy: 0.7653\n",
      "[Epoch 0][Batch 141][Samples 4544] time/batch: 0.261s training loss: 0.4848, training accuracy: 0.7658\n",
      "[Epoch 0][Batch 142][Samples 4576] time/batch: 0.259s training loss: 0.4848, training accuracy: 0.7655\n",
      "[Epoch 0][Batch 143][Samples 4608] time/batch: 0.265s training loss: 0.4840, training accuracy: 0.7663\n",
      "[Epoch 0][Batch 144][Samples 4640] time/batch: 0.268s training loss: 0.4835, training accuracy: 0.7666\n",
      "[Epoch 0][Batch 145][Samples 4672] time/batch: 0.264s training loss: 0.4818, training accuracy: 0.7678\n",
      "[Epoch 0][Batch 146][Samples 4704] time/batch: 0.266s training loss: 0.4822, training accuracy: 0.7676\n",
      "[Epoch 0][Batch 147][Samples 4736] time/batch: 0.258s training loss: 0.4826, training accuracy: 0.7677\n",
      "[Epoch 0][Batch 148][Samples 4768] time/batch: 0.264s training loss: 0.4831, training accuracy: 0.7676\n",
      "[Epoch 0][Batch 149][Samples 4800] time/batch: 0.259s training loss: 0.4834, training accuracy: 0.7679\n",
      "[Epoch 0][Batch 150][Samples 4832] time/batch: 0.266s training loss: 0.4824, training accuracy: 0.7684\n",
      "[Epoch 0][Batch 151][Samples 4864] time/batch: 0.258s training loss: 0.4819, training accuracy: 0.7691\n",
      "[Epoch 0][Batch 152][Samples 4896] time/batch: 0.266s training loss: 0.4820, training accuracy: 0.7690\n",
      "[Epoch 0][Batch 153][Samples 4928] time/batch: 0.259s training loss: 0.4824, training accuracy: 0.7687\n",
      "[Epoch 0][Batch 154][Samples 4960] time/batch: 0.261s training loss: 0.4822, training accuracy: 0.7694\n",
      "[Epoch 0][Batch 155][Samples 4992] time/batch: 0.259s training loss: 0.4817, training accuracy: 0.7696\n",
      "[Epoch 0][Batch 156][Samples 5024] time/batch: 0.266s training loss: 0.4807, training accuracy: 0.7701\n",
      "[Epoch 0][Batch 157][Samples 5056] time/batch: 0.260s training loss: 0.4797, training accuracy: 0.7708\n",
      "[Epoch 0][Batch 158][Samples 5088] time/batch: 0.266s training loss: 0.4796, training accuracy: 0.7710\n",
      "[Epoch 0][Batch 159][Samples 5120] time/batch: 0.260s training loss: 0.4786, training accuracy: 0.7717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 160][Samples 5152] time/batch: 0.261s training loss: 0.4779, training accuracy: 0.7719\n",
      "[Epoch 0][Batch 161][Samples 5184] time/batch: 0.260s training loss: 0.4769, training accuracy: 0.7728\n",
      "[Epoch 0][Batch 162][Samples 5216] time/batch: 0.257s training loss: 0.4765, training accuracy: 0.7736\n",
      "[Epoch 0][Batch 163][Samples 5248] time/batch: 0.258s training loss: 0.4742, training accuracy: 0.7748\n",
      "[Epoch 0][Batch 164][Samples 5280] time/batch: 0.257s training loss: 0.4728, training accuracy: 0.7756\n",
      "[Epoch 0][Batch 165][Samples 5312] time/batch: 0.263s training loss: 0.4735, training accuracy: 0.7756\n",
      "[Epoch 0][Batch 166][Samples 5344] time/batch: 0.269s training loss: 0.4718, training accuracy: 0.7762\n",
      "[Epoch 0][Batch 167][Samples 5376] time/batch: 0.274s training loss: 0.4727, training accuracy: 0.7762\n",
      "[Epoch 0][Batch 168][Samples 5408] time/batch: 0.267s training loss: 0.4741, training accuracy: 0.7761\n",
      "[Epoch 0][Batch 169][Samples 5440] time/batch: 0.271s training loss: 0.4743, training accuracy: 0.7761\n",
      "[Epoch 0][Batch 170][Samples 5472] time/batch: 0.268s training loss: 0.4759, training accuracy: 0.7758\n",
      "[Epoch 0][Batch 171][Samples 5504] time/batch: 0.264s training loss: 0.4745, training accuracy: 0.7767\n",
      "[Epoch 0][Batch 172][Samples 5536] time/batch: 0.257s training loss: 0.4730, training accuracy: 0.7775\n",
      "[Epoch 0][Batch 173][Samples 5568] time/batch: 0.260s training loss: 0.4737, training accuracy: 0.7769\n",
      "[Epoch 0][Batch 174][Samples 5600] time/batch: 0.261s training loss: 0.4724, training accuracy: 0.7775\n",
      "[Epoch 0][Batch 175][Samples 5632] time/batch: 0.268s training loss: 0.4730, training accuracy: 0.7773\n",
      "[Epoch 0][Batch 176][Samples 5664] time/batch: 0.272s training loss: 0.4727, training accuracy: 0.7775\n",
      "[Epoch 0][Batch 177][Samples 5696] time/batch: 0.271s training loss: 0.4730, training accuracy: 0.7772\n",
      "[Epoch 0][Batch 178][Samples 5728] time/batch: 0.269s training loss: 0.4732, training accuracy: 0.7771\n",
      "[Epoch 0][Batch 179][Samples 5760] time/batch: 0.268s training loss: 0.4724, training accuracy: 0.7781\n",
      "[Epoch 0][Batch 180][Samples 5792] time/batch: 0.273s training loss: 0.4718, training accuracy: 0.7787\n",
      "[Epoch 0][Batch 181][Samples 5824] time/batch: 0.270s training loss: 0.4717, training accuracy: 0.7785\n",
      "[Epoch 0][Batch 182][Samples 5856] time/batch: 0.269s training loss: 0.4711, training accuracy: 0.7785\n",
      "[Epoch 0][Batch 183][Samples 5888] time/batch: 0.259s training loss: 0.4703, training accuracy: 0.7787\n",
      "[Epoch 0][Batch 184][Samples 5920] time/batch: 0.260s training loss: 0.4707, training accuracy: 0.7787\n",
      "[Epoch 0][Batch 185][Samples 5952] time/batch: 0.258s training loss: 0.4704, training accuracy: 0.7789\n",
      "[Epoch 0][Batch 186][Samples 5984] time/batch: 0.263s training loss: 0.4707, training accuracy: 0.7782\n",
      "[Epoch 0][Batch 187][Samples 6016] time/batch: 0.267s training loss: 0.4703, training accuracy: 0.7784\n",
      "[Epoch 0][Batch 188][Samples 6048] time/batch: 0.263s training loss: 0.4703, training accuracy: 0.7786\n",
      "[Epoch 0][Batch 189][Samples 6080] time/batch: 0.264s training loss: 0.4697, training accuracy: 0.7788\n",
      "[Epoch 0][Batch 190][Samples 6112] time/batch: 0.262s training loss: 0.4685, training accuracy: 0.7793\n",
      "[Epoch 0][Batch 191][Samples 6144] time/batch: 0.267s training loss: 0.4680, training accuracy: 0.7795\n",
      "[Epoch 0][Batch 192][Samples 6176] time/batch: 0.259s training loss: 0.4666, training accuracy: 0.7804\n",
      "[Epoch 0][Batch 193][Samples 6208] time/batch: 0.258s training loss: 0.4656, training accuracy: 0.7809\n",
      "[Epoch 0][Batch 194][Samples 6240] time/batch: 0.267s training loss: 0.4647, training accuracy: 0.7817\n",
      "[Epoch 0][Batch 195][Samples 6272] time/batch: 0.261s training loss: 0.4636, training accuracy: 0.7822\n",
      "[Epoch 0][Batch 196][Samples 6304] time/batch: 0.266s training loss: 0.4629, training accuracy: 0.7824\n",
      "[Epoch 0][Batch 197][Samples 6336] time/batch: 0.271s training loss: 0.4624, training accuracy: 0.7828\n",
      "[Epoch 0][Batch 198][Samples 6368] time/batch: 0.257s training loss: 0.4619, training accuracy: 0.7831\n",
      "[Epoch 0][Batch 199][Samples 6400] time/batch: 0.261s training loss: 0.4616, training accuracy: 0.7834\n",
      "[Epoch 0][Batch 200][Samples 6432] time/batch: 0.260s training loss: 0.4618, training accuracy: 0.7831\n",
      "[Epoch 0][Batch 201][Samples 6464] time/batch: 0.265s training loss: 0.4615, training accuracy: 0.7834\n",
      "[Epoch 0][Batch 202][Samples 6496] time/batch: 0.270s training loss: 0.4613, training accuracy: 0.7834\n",
      "[Epoch 0][Batch 203][Samples 6528] time/batch: 0.260s training loss: 0.4599, training accuracy: 0.7842\n",
      "[Epoch 0][Batch 204][Samples 6560] time/batch: 0.272s training loss: 0.4595, training accuracy: 0.7841\n",
      "[Epoch 0][Batch 205][Samples 6592] time/batch: 0.262s training loss: 0.4590, training accuracy: 0.7844\n",
      "[Epoch 0][Batch 206][Samples 6624] time/batch: 0.260s training loss: 0.4590, training accuracy: 0.7846\n",
      "[Epoch 0][Batch 207][Samples 6656] time/batch: 0.259s training loss: 0.4589, training accuracy: 0.7850\n",
      "[Epoch 0][Batch 208][Samples 6688] time/batch: 0.259s training loss: 0.4580, training accuracy: 0.7854\n",
      "[Epoch 0][Batch 209][Samples 6720] time/batch: 0.261s training loss: 0.4581, training accuracy: 0.7853\n",
      "[Epoch 0][Batch 210][Samples 6752] time/batch: 0.260s training loss: 0.4579, training accuracy: 0.7855\n",
      "[Epoch 0][Batch 211][Samples 6784] time/batch: 0.273s training loss: 0.4584, training accuracy: 0.7852\n",
      "[Epoch 0][Batch 212][Samples 6816] time/batch: 0.270s training loss: 0.4577, training accuracy: 0.7858\n",
      "[Epoch 0][Batch 213][Samples 6848] time/batch: 0.268s training loss: 0.4570, training accuracy: 0.7861\n",
      "[Epoch 0][Batch 214][Samples 6880] time/batch: 0.259s training loss: 0.4569, training accuracy: 0.7859\n",
      "[Epoch 0][Batch 215][Samples 6912] time/batch: 0.263s training loss: 0.4558, training accuracy: 0.7863\n",
      "[Epoch 0][Batch 216][Samples 6944] time/batch: 0.267s training loss: 0.4550, training accuracy: 0.7866\n",
      "[Epoch 0][Batch 217][Samples 6976] time/batch: 0.274s training loss: 0.4540, training accuracy: 0.7871\n",
      "[Epoch 0][Batch 218][Samples 7008] time/batch: 0.262s training loss: 0.4541, training accuracy: 0.7874\n",
      "[Epoch 0][Batch 219][Samples 7040] time/batch: 0.260s training loss: 0.4535, training accuracy: 0.7875\n",
      "[Epoch 0][Batch 220][Samples 7072] time/batch: 0.272s training loss: 0.4527, training accuracy: 0.7879\n",
      "[Epoch 0][Batch 221][Samples 7104] time/batch: 0.258s training loss: 0.4522, training accuracy: 0.7883\n",
      "[Epoch 0][Batch 222][Samples 7136] time/batch: 0.265s training loss: 0.4517, training accuracy: 0.7887\n",
      "[Epoch 0][Batch 223][Samples 7168] time/batch: 0.258s training loss: 0.4515, training accuracy: 0.7889\n",
      "[Epoch 0][Batch 224][Samples 7200] time/batch: 0.267s training loss: 0.4512, training accuracy: 0.7892\n",
      "[Epoch 0][Batch 225][Samples 7232] time/batch: 0.258s training loss: 0.4512, training accuracy: 0.7891\n",
      "[Epoch 0][Batch 226][Samples 7264] time/batch: 0.263s training loss: 0.4505, training accuracy: 0.7896\n",
      "[Epoch 0][Batch 227][Samples 7296] time/batch: 0.269s training loss: 0.4498, training accuracy: 0.7900\n",
      "[Epoch 0][Batch 228][Samples 7328] time/batch: 0.273s training loss: 0.4495, training accuracy: 0.7904\n",
      "[Epoch 0][Batch 229][Samples 7360] time/batch: 0.270s training loss: 0.4487, training accuracy: 0.7906\n",
      "[Epoch 0][Batch 230][Samples 7392] time/batch: 0.268s training loss: 0.4480, training accuracy: 0.7911\n",
      "[Epoch 0][Batch 231][Samples 7424] time/batch: 0.265s training loss: 0.4475, training accuracy: 0.7914\n",
      "[Epoch 0][Batch 232][Samples 7456] time/batch: 0.273s training loss: 0.4470, training accuracy: 0.7910\n",
      "[Epoch 0][Batch 233][Samples 7488] time/batch: 0.270s training loss: 0.4460, training accuracy: 0.7915\n",
      "[Epoch 0][Batch 234][Samples 7520] time/batch: 0.266s training loss: 0.4457, training accuracy: 0.7915\n",
      "[Epoch 0][Batch 235][Samples 7552] time/batch: 0.260s training loss: 0.4461, training accuracy: 0.7914\n",
      "[Epoch 0][Batch 236][Samples 7584] time/batch: 0.258s training loss: 0.4450, training accuracy: 0.7921\n",
      "[Epoch 0][Batch 237][Samples 7616] time/batch: 0.264s training loss: 0.4454, training accuracy: 0.7916\n",
      "[Epoch 0][Batch 238][Samples 7648] time/batch: 0.258s training loss: 0.4451, training accuracy: 0.7916\n",
      "[Epoch 0][Batch 239][Samples 7680] time/batch: 0.265s training loss: 0.4447, training accuracy: 0.7915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 240][Samples 7712] time/batch: 0.269s training loss: 0.4438, training accuracy: 0.7918\n",
      "[Epoch 0][Batch 241][Samples 7744] time/batch: 0.265s training loss: 0.4437, training accuracy: 0.7920\n",
      "[Epoch 0][Batch 242][Samples 7776] time/batch: 0.262s training loss: 0.4434, training accuracy: 0.7919\n",
      "[Epoch 0][Batch 243][Samples 7808] time/batch: 0.265s training loss: 0.4429, training accuracy: 0.7923\n",
      "[Epoch 0][Batch 244][Samples 7840] time/batch: 0.265s training loss: 0.4429, training accuracy: 0.7922\n",
      "[Epoch 0][Batch 245][Samples 7872] time/batch: 0.260s training loss: 0.4426, training accuracy: 0.7923\n",
      "[Epoch 0][Batch 246][Samples 7904] time/batch: 0.268s training loss: 0.4417, training accuracy: 0.7926\n",
      "[Epoch 0][Batch 247][Samples 7936] time/batch: 0.264s training loss: 0.4414, training accuracy: 0.7926\n",
      "[Epoch 0][Batch 248][Samples 7968] time/batch: 0.258s training loss: 0.4411, training accuracy: 0.7928\n",
      "[Epoch 0][Batch 249][Samples 8000] time/batch: 0.264s training loss: 0.4407, training accuracy: 0.7930\n",
      "[Epoch 0][Batch 250][Samples 8032] time/batch: 0.268s training loss: 0.4401, training accuracy: 0.7933\n",
      "[Epoch 0][Batch 251][Samples 8064] time/batch: 0.271s training loss: 0.4399, training accuracy: 0.7938\n",
      "[Epoch 0][Batch 252][Samples 8096] time/batch: 0.261s training loss: 0.4390, training accuracy: 0.7941\n",
      "[Epoch 0][Batch 253][Samples 8128] time/batch: 0.258s training loss: 0.4391, training accuracy: 0.7940\n",
      "[Epoch 0][Batch 254][Samples 8160] time/batch: 0.268s training loss: 0.4394, training accuracy: 0.7939\n",
      "[Epoch 0][Batch 255][Samples 8192] time/batch: 0.266s training loss: 0.4397, training accuracy: 0.7938\n",
      "[Epoch 0][Batch 256][Samples 8224] time/batch: 0.261s training loss: 0.4395, training accuracy: 0.7938\n",
      "[Epoch 0][Batch 257][Samples 8256] time/batch: 0.266s training loss: 0.4391, training accuracy: 0.7940\n",
      "[Epoch 0][Batch 258][Samples 8288] time/batch: 0.258s training loss: 0.4388, training accuracy: 0.7942\n",
      "[Epoch 0][Batch 259][Samples 8320] time/batch: 0.259s training loss: 0.4386, training accuracy: 0.7942\n",
      "[Epoch 0][Batch 260][Samples 8352] time/batch: 0.262s training loss: 0.4384, training accuracy: 0.7943\n",
      "[Epoch 0][Batch 261][Samples 8384] time/batch: 0.261s training loss: 0.4373, training accuracy: 0.7951\n",
      "[Epoch 0][Batch 262][Samples 8416] time/batch: 0.259s training loss: 0.4367, training accuracy: 0.7953\n",
      "[Epoch 0][Batch 263][Samples 8448] time/batch: 0.260s training loss: 0.4366, training accuracy: 0.7955\n",
      "[Epoch 0][Batch 264][Samples 8480] time/batch: 0.259s training loss: 0.4366, training accuracy: 0.7958\n",
      "[Epoch 0][Batch 265][Samples 8512] time/batch: 0.262s training loss: 0.4359, training accuracy: 0.7961\n",
      "[Epoch 0][Batch 266][Samples 8544] time/batch: 0.259s training loss: 0.4348, training accuracy: 0.7967\n",
      "[Epoch 0][Batch 267][Samples 8576] time/batch: 0.261s training loss: 0.4350, training accuracy: 0.7965\n",
      "[Epoch 0][Batch 268][Samples 8608] time/batch: 0.264s training loss: 0.4342, training accuracy: 0.7968\n",
      "[Epoch 0][Batch 269][Samples 8640] time/batch: 0.267s training loss: 0.4347, training accuracy: 0.7968\n",
      "[Epoch 0][Batch 270][Samples 8672] time/batch: 0.258s training loss: 0.4344, training accuracy: 0.7968\n",
      "[Epoch 0][Batch 271][Samples 8704] time/batch: 0.265s training loss: 0.4337, training accuracy: 0.7971\n",
      "[Epoch 0][Batch 272][Samples 8736] time/batch: 0.258s training loss: 0.4329, training accuracy: 0.7973\n",
      "[Epoch 0][Batch 273][Samples 8768] time/batch: 0.261s training loss: 0.4329, training accuracy: 0.7973\n",
      "[Epoch 0][Batch 274][Samples 8800] time/batch: 0.259s training loss: 0.4323, training accuracy: 0.7977\n",
      "[Epoch 0][Batch 275][Samples 8832] time/batch: 0.263s training loss: 0.4323, training accuracy: 0.7978\n",
      "[Epoch 0][Batch 276][Samples 8864] time/batch: 0.261s training loss: 0.4326, training accuracy: 0.7977\n",
      "[Epoch 0][Batch 277][Samples 8896] time/batch: 0.265s training loss: 0.4321, training accuracy: 0.7979\n",
      "[Epoch 0][Batch 278][Samples 8928] time/batch: 0.260s training loss: 0.4317, training accuracy: 0.7981\n",
      "[Epoch 0][Batch 279][Samples 8960] time/batch: 0.265s training loss: 0.4310, training accuracy: 0.7982\n",
      "[Epoch 0][Batch 280][Samples 8992] time/batch: 0.260s training loss: 0.4311, training accuracy: 0.7985\n",
      "[Epoch 0][Batch 281][Samples 9024] time/batch: 0.264s training loss: 0.4305, training accuracy: 0.7988\n",
      "[Epoch 0][Batch 282][Samples 9056] time/batch: 0.269s training loss: 0.4298, training accuracy: 0.7994\n",
      "[Epoch 0][Batch 283][Samples 9088] time/batch: 0.273s training loss: 0.4292, training accuracy: 0.7995\n",
      "[Epoch 0][Batch 284][Samples 9120] time/batch: 0.267s training loss: 0.4299, training accuracy: 0.7991\n",
      "[Epoch 0][Batch 285][Samples 9152] time/batch: 0.259s training loss: 0.4296, training accuracy: 0.7994\n",
      "[Epoch 0][Batch 286][Samples 9184] time/batch: 0.264s training loss: 0.4288, training accuracy: 0.7998\n",
      "[Epoch 0][Batch 287][Samples 9216] time/batch: 0.258s training loss: 0.4278, training accuracy: 0.8002\n",
      "[Epoch 0][Batch 288][Samples 9248] time/batch: 0.263s training loss: 0.4268, training accuracy: 0.8008\n",
      "[Epoch 0][Batch 289][Samples 9280] time/batch: 0.258s training loss: 0.4270, training accuracy: 0.8006\n",
      "[Epoch 0][Batch 290][Samples 9312] time/batch: 0.260s training loss: 0.4267, training accuracy: 0.8007\n",
      "[Epoch 0][Batch 291][Samples 9344] time/batch: 0.268s training loss: 0.4263, training accuracy: 0.8012\n",
      "[Epoch 0][Batch 292][Samples 9376] time/batch: 0.275s training loss: 0.4256, training accuracy: 0.8014\n",
      "[Epoch 0][Batch 293][Samples 9408] time/batch: 0.260s training loss: 0.4254, training accuracy: 0.8016\n",
      "[Epoch 0][Batch 294][Samples 9440] time/batch: 0.260s training loss: 0.4246, training accuracy: 0.8019\n",
      "[Epoch 0][Batch 295][Samples 9472] time/batch: 0.269s training loss: 0.4242, training accuracy: 0.8020\n",
      "[Epoch 0][Batch 296][Samples 9504] time/batch: 0.264s training loss: 0.4234, training accuracy: 0.8025\n",
      "[Epoch 0][Batch 297][Samples 9536] time/batch: 0.259s training loss: 0.4223, training accuracy: 0.8030\n",
      "[Epoch 0][Batch 298][Samples 9568] time/batch: 0.259s training loss: 0.4224, training accuracy: 0.8029\n",
      "[Epoch 0][Batch 299][Samples 9600] time/batch: 0.260s training loss: 0.4231, training accuracy: 0.8027\n",
      "[Epoch 0][Batch 300][Samples 9632] time/batch: 0.260s training loss: 0.4230, training accuracy: 0.8028\n",
      "[Epoch 0][Batch 301][Samples 9664] time/batch: 0.261s training loss: 0.4219, training accuracy: 0.8033\n",
      "[Epoch 0][Batch 302][Samples 9696] time/batch: 0.259s training loss: 0.4221, training accuracy: 0.8034\n",
      "[Epoch 0][Batch 303][Samples 9728] time/batch: 0.269s training loss: 0.4219, training accuracy: 0.8037\n",
      "[Epoch 0][Batch 304][Samples 9760] time/batch: 0.268s training loss: 0.4211, training accuracy: 0.8040\n",
      "[Epoch 0][Batch 305][Samples 9792] time/batch: 0.276s training loss: 0.4216, training accuracy: 0.8040\n",
      "[Epoch 0][Batch 306][Samples 9824] time/batch: 0.263s training loss: 0.4208, training accuracy: 0.8044\n",
      "[Epoch 0][Batch 307][Samples 9856] time/batch: 0.269s training loss: 0.4206, training accuracy: 0.8045\n",
      "[Epoch 0][Batch 308][Samples 9888] time/batch: 0.269s training loss: 0.4201, training accuracy: 0.8046\n",
      "[Epoch 0][Batch 309][Samples 9920] time/batch: 0.265s training loss: 0.4200, training accuracy: 0.8046\n",
      "[Epoch 0][Batch 310][Samples 9952] time/batch: 0.258s training loss: 0.4197, training accuracy: 0.8046\n",
      "[Epoch 0][Batch 311][Samples 9984] time/batch: 0.264s training loss: 0.4197, training accuracy: 0.8047\n",
      "[Epoch 0][Batch 312][Samples 10016] time/batch: 0.261s training loss: 0.4195, training accuracy: 0.8046\n",
      "[Epoch 0][Batch 313][Samples 10048] time/batch: 0.266s training loss: 0.4199, training accuracy: 0.8044\n",
      "[Epoch 0][Batch 314][Samples 10080] time/batch: 0.270s training loss: 0.4193, training accuracy: 0.8048\n",
      "[Epoch 0][Batch 315][Samples 10112] time/batch: 0.261s training loss: 0.4195, training accuracy: 0.8050\n",
      "[Epoch 0][Batch 316][Samples 10144] time/batch: 0.259s training loss: 0.4201, training accuracy: 0.8047\n",
      "[Epoch 0][Batch 317][Samples 10176] time/batch: 0.265s training loss: 0.4199, training accuracy: 0.8047\n",
      "[Epoch 0][Batch 318][Samples 10208] time/batch: 0.260s training loss: 0.4193, training accuracy: 0.8052\n",
      "[Epoch 0][Batch 319][Samples 10240] time/batch: 0.260s training loss: 0.4188, training accuracy: 0.8056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 320][Samples 10272] time/batch: 0.263s training loss: 0.4184, training accuracy: 0.8057\n",
      "[Epoch 0][Batch 321][Samples 10304] time/batch: 0.273s training loss: 0.4188, training accuracy: 0.8054\n",
      "[Epoch 0][Batch 322][Samples 10336] time/batch: 0.271s training loss: 0.4187, training accuracy: 0.8056\n",
      "[Epoch 0][Batch 323][Samples 10368] time/batch: 0.260s training loss: 0.4182, training accuracy: 0.8057\n",
      "[Epoch 0][Batch 324][Samples 10400] time/batch: 0.263s training loss: 0.4176, training accuracy: 0.8060\n",
      "[Epoch 0][Batch 325][Samples 10432] time/batch: 0.260s training loss: 0.4179, training accuracy: 0.8059\n",
      "[Epoch 0][Batch 326][Samples 10464] time/batch: 0.270s training loss: 0.4180, training accuracy: 0.8059\n",
      "[Epoch 0][Batch 327][Samples 10496] time/batch: 0.269s training loss: 0.4177, training accuracy: 0.8060\n",
      "[Epoch 0][Batch 328][Samples 10528] time/batch: 0.265s training loss: 0.4178, training accuracy: 0.8059\n",
      "[Epoch 0][Batch 329][Samples 10560] time/batch: 0.261s training loss: 0.4176, training accuracy: 0.8061\n",
      "[Epoch 0][Batch 330][Samples 10592] time/batch: 0.268s training loss: 0.4175, training accuracy: 0.8063\n",
      "[Epoch 0][Batch 331][Samples 10624] time/batch: 0.260s training loss: 0.4175, training accuracy: 0.8062\n",
      "[Epoch 0][Batch 332][Samples 10656] time/batch: 0.277s training loss: 0.4172, training accuracy: 0.8064\n",
      "[Epoch 0][Batch 333][Samples 10688] time/batch: 0.267s training loss: 0.4167, training accuracy: 0.8066\n",
      "[Epoch 0][Batch 334][Samples 10720] time/batch: 0.261s training loss: 0.4165, training accuracy: 0.8066\n",
      "[Epoch 0][Batch 335][Samples 10752] time/batch: 0.261s training loss: 0.4161, training accuracy: 0.8067\n",
      "[Epoch 0][Batch 336][Samples 10784] time/batch: 0.261s training loss: 0.4158, training accuracy: 0.8071\n",
      "[Epoch 0][Batch 337][Samples 10816] time/batch: 0.277s training loss: 0.4155, training accuracy: 0.8072\n",
      "[Epoch 0][Batch 338][Samples 10848] time/batch: 0.270s training loss: 0.4151, training accuracy: 0.8072\n",
      "[Epoch 0][Batch 339][Samples 10880] time/batch: 0.274s training loss: 0.4147, training accuracy: 0.8074\n",
      "[Epoch 0][Batch 340][Samples 10912] time/batch: 0.260s training loss: 0.4145, training accuracy: 0.8075\n",
      "[Epoch 0][Batch 341][Samples 10944] time/batch: 0.270s training loss: 0.4147, training accuracy: 0.8072\n",
      "[Epoch 0][Batch 342][Samples 10976] time/batch: 0.274s training loss: 0.4145, training accuracy: 0.8073\n",
      "[Epoch 0][Batch 343][Samples 11008] time/batch: 0.270s training loss: 0.4137, training accuracy: 0.8077\n",
      "[Epoch 0][Batch 344][Samples 11040] time/batch: 0.273s training loss: 0.4136, training accuracy: 0.8077\n",
      "[Epoch 0][Batch 345][Samples 11072] time/batch: 0.269s training loss: 0.4130, training accuracy: 0.8081\n",
      "[Epoch 0][Batch 346][Samples 11104] time/batch: 0.274s training loss: 0.4124, training accuracy: 0.8084\n",
      "[Epoch 0][Batch 347][Samples 11136] time/batch: 0.261s training loss: 0.4124, training accuracy: 0.8085\n",
      "[Epoch 0][Batch 348][Samples 11168] time/batch: 0.259s training loss: 0.4129, training accuracy: 0.8084\n",
      "[Epoch 0][Batch 349][Samples 11200] time/batch: 0.276s training loss: 0.4130, training accuracy: 0.8084\n",
      "[Epoch 0][Batch 350][Samples 11232] time/batch: 0.272s training loss: 0.4130, training accuracy: 0.8084\n",
      "[Epoch 0][Batch 351][Samples 11264] time/batch: 0.278s training loss: 0.4137, training accuracy: 0.8082\n",
      "[Epoch 0][Batch 352][Samples 11296] time/batch: 0.263s training loss: 0.4142, training accuracy: 0.8082\n",
      "[Epoch 0][Batch 353][Samples 11328] time/batch: 0.260s training loss: 0.4145, training accuracy: 0.8079\n",
      "[Epoch 0][Batch 354][Samples 11360] time/batch: 0.268s training loss: 0.4143, training accuracy: 0.8079\n",
      "[Epoch 0][Batch 355][Samples 11392] time/batch: 0.262s training loss: 0.4143, training accuracy: 0.8078\n",
      "[Epoch 0][Batch 356][Samples 11424] time/batch: 0.269s training loss: 0.4144, training accuracy: 0.8081\n",
      "[Epoch 0][Batch 357][Samples 11456] time/batch: 0.269s training loss: 0.4143, training accuracy: 0.8083\n",
      "[Epoch 0][Batch 358][Samples 11488] time/batch: 0.261s training loss: 0.4140, training accuracy: 0.8084\n",
      "[Epoch 0][Batch 359][Samples 11520] time/batch: 0.270s training loss: 0.4143, training accuracy: 0.8082\n",
      "[Epoch 0][Batch 360][Samples 11552] time/batch: 0.262s training loss: 0.4144, training accuracy: 0.8083\n",
      "[Epoch 0][Batch 361][Samples 11584] time/batch: 0.261s training loss: 0.4142, training accuracy: 0.8082\n",
      "[Epoch 0][Batch 362][Samples 11616] time/batch: 0.261s training loss: 0.4140, training accuracy: 0.8084\n",
      "[Epoch 0][Batch 363][Samples 11648] time/batch: 0.263s training loss: 0.4137, training accuracy: 0.8087\n",
      "[Epoch 0][Batch 364][Samples 11680] time/batch: 0.260s training loss: 0.4131, training accuracy: 0.8092\n",
      "[Epoch 0][Batch 365][Samples 11712] time/batch: 0.263s training loss: 0.4128, training accuracy: 0.8094\n",
      "[Epoch 0][Batch 366][Samples 11744] time/batch: 0.262s training loss: 0.4124, training accuracy: 0.8096\n",
      "[Epoch 0][Batch 367][Samples 11776] time/batch: 0.265s training loss: 0.4128, training accuracy: 0.8097\n",
      "[Epoch 0][Batch 368][Samples 11808] time/batch: 0.261s training loss: 0.4131, training accuracy: 0.8096\n",
      "[Epoch 0][Batch 369][Samples 11840] time/batch: 0.270s training loss: 0.4133, training accuracy: 0.8095\n",
      "[Epoch 0][Batch 370][Samples 11872] time/batch: 0.263s training loss: 0.4131, training accuracy: 0.8098\n",
      "[Epoch 0][Batch 371][Samples 11904] time/batch: 0.264s training loss: 0.4128, training accuracy: 0.8099\n",
      "[Epoch 0][Batch 372][Samples 11936] time/batch: 0.262s training loss: 0.4129, training accuracy: 0.8099\n",
      "[Epoch 0][Batch 373][Samples 11968] time/batch: 0.268s training loss: 0.4124, training accuracy: 0.8101\n",
      "[Epoch 0][Batch 374][Samples 12000] time/batch: 0.259s training loss: 0.4122, training accuracy: 0.8103\n",
      "[Epoch 0][Batch 375][Samples 12032] time/batch: 0.264s training loss: 0.4121, training accuracy: 0.8103\n",
      "[Epoch 0][Batch 376][Samples 12064] time/batch: 0.260s training loss: 0.4119, training accuracy: 0.8104\n",
      "[Epoch 0][Batch 377][Samples 12096] time/batch: 0.264s training loss: 0.4120, training accuracy: 0.8102\n",
      "[Epoch 0][Batch 378][Samples 12128] time/batch: 0.259s training loss: 0.4114, training accuracy: 0.8104\n",
      "[Epoch 0][Batch 379][Samples 12160] time/batch: 0.264s training loss: 0.4112, training accuracy: 0.8105\n",
      "[Epoch 0][Batch 380][Samples 12192] time/batch: 0.259s training loss: 0.4111, training accuracy: 0.8107\n",
      "[Epoch 0][Batch 381][Samples 12224] time/batch: 0.259s training loss: 0.4108, training accuracy: 0.8109\n",
      "[Epoch 0][Batch 382][Samples 12256] time/batch: 0.260s training loss: 0.4110, training accuracy: 0.8109\n",
      "[Epoch 0][Batch 383][Samples 12288] time/batch: 0.265s training loss: 0.4106, training accuracy: 0.8113\n",
      "[Epoch 0][Batch 384][Samples 12320] time/batch: 0.264s training loss: 0.4104, training accuracy: 0.8114\n",
      "[Epoch 0][Batch 385][Samples 12352] time/batch: 0.259s training loss: 0.4101, training accuracy: 0.8114\n",
      "[Epoch 0][Batch 386][Samples 12384] time/batch: 0.269s training loss: 0.4097, training accuracy: 0.8116\n",
      "[Epoch 0][Batch 387][Samples 12416] time/batch: 0.263s training loss: 0.4097, training accuracy: 0.8117\n",
      "[Epoch 0][Batch 388][Samples 12448] time/batch: 0.268s training loss: 0.4094, training accuracy: 0.8119\n",
      "[Epoch 0][Batch 389][Samples 12480] time/batch: 0.264s training loss: 0.4095, training accuracy: 0.8119\n",
      "[Epoch 0][Batch 390][Samples 12512] time/batch: 0.264s training loss: 0.4092, training accuracy: 0.8119\n",
      "[Epoch 0][Batch 391][Samples 12544] time/batch: 0.268s training loss: 0.4093, training accuracy: 0.8119\n",
      "[Epoch 0][Batch 392][Samples 12576] time/batch: 0.262s training loss: 0.4093, training accuracy: 0.8120\n",
      "[Epoch 0][Batch 393][Samples 12608] time/batch: 0.270s training loss: 0.4091, training accuracy: 0.8123\n",
      "[Epoch 0][Batch 394][Samples 12640] time/batch: 0.263s training loss: 0.4091, training accuracy: 0.8123\n",
      "[Epoch 0][Batch 395][Samples 12672] time/batch: 0.271s training loss: 0.4087, training accuracy: 0.8124\n",
      "[Epoch 0][Batch 396][Samples 12704] time/batch: 0.272s training loss: 0.4086, training accuracy: 0.8123\n",
      "[Epoch 0][Batch 397][Samples 12736] time/batch: 0.259s training loss: 0.4086, training accuracy: 0.8123\n",
      "[Epoch 0][Batch 398][Samples 12768] time/batch: 0.265s training loss: 0.4088, training accuracy: 0.8122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 399][Samples 12800] time/batch: 0.260s training loss: 0.4085, training accuracy: 0.8123\n",
      "[Epoch 0][Batch 400][Samples 12832] time/batch: 0.260s training loss: 0.4082, training accuracy: 0.8125\n",
      "[Epoch 0][Batch 401][Samples 12864] time/batch: 0.268s training loss: 0.4076, training accuracy: 0.8129\n",
      "[Epoch 0][Batch 402][Samples 12896] time/batch: 0.262s training loss: 0.4076, training accuracy: 0.8130\n",
      "[Epoch 0][Batch 403][Samples 12928] time/batch: 0.269s training loss: 0.4073, training accuracy: 0.8132\n",
      "[Epoch 0][Batch 404][Samples 12960] time/batch: 0.272s training loss: 0.4076, training accuracy: 0.8132\n",
      "[Epoch 0][Batch 405][Samples 12992] time/batch: 0.266s training loss: 0.4077, training accuracy: 0.8129\n",
      "[Epoch 0][Batch 406][Samples 13024] time/batch: 0.262s training loss: 0.4074, training accuracy: 0.8130\n",
      "[Epoch 0][Batch 407][Samples 13056] time/batch: 0.268s training loss: 0.4069, training accuracy: 0.8133\n",
      "[Epoch 0][Batch 408][Samples 13088] time/batch: 0.267s training loss: 0.4066, training accuracy: 0.8134\n",
      "[Epoch 0][Batch 409][Samples 13120] time/batch: 0.261s training loss: 0.4066, training accuracy: 0.8134\n",
      "[Epoch 0][Batch 410][Samples 13152] time/batch: 0.270s training loss: 0.4066, training accuracy: 0.8135\n",
      "[Epoch 0][Batch 411][Samples 13184] time/batch: 0.264s training loss: 0.4063, training accuracy: 0.8137\n",
      "[Epoch 0][Batch 412][Samples 13216] time/batch: 0.271s training loss: 0.4058, training accuracy: 0.8139\n",
      "[Epoch 0][Batch 413][Samples 13248] time/batch: 0.264s training loss: 0.4057, training accuracy: 0.8140\n",
      "[Epoch 0][Batch 414][Samples 13280] time/batch: 0.270s training loss: 0.4054, training accuracy: 0.8141\n",
      "[Epoch 0][Batch 415][Samples 13312] time/batch: 0.266s training loss: 0.4053, training accuracy: 0.8142\n",
      "[Epoch 0][Batch 416][Samples 13344] time/batch: 0.261s training loss: 0.4056, training accuracy: 0.8140\n",
      "[Epoch 0][Batch 417][Samples 13376] time/batch: 0.271s training loss: 0.4056, training accuracy: 0.8141\n",
      "[Epoch 0][Batch 418][Samples 13408] time/batch: 0.264s training loss: 0.4054, training accuracy: 0.8144\n",
      "[Epoch 0][Batch 419][Samples 13440] time/batch: 0.262s training loss: 0.4054, training accuracy: 0.8143\n",
      "[Epoch 0][Batch 420][Samples 13472] time/batch: 0.272s training loss: 0.4051, training accuracy: 0.8143\n",
      "[Epoch 0][Batch 421][Samples 13504] time/batch: 0.268s training loss: 0.4051, training accuracy: 0.8144\n",
      "[Epoch 0][Batch 422][Samples 13536] time/batch: 0.262s training loss: 0.4048, training accuracy: 0.8146\n",
      "[Epoch 0][Batch 423][Samples 13568] time/batch: 0.266s training loss: 0.4043, training accuracy: 0.8148\n",
      "[Epoch 0][Batch 424][Samples 13600] time/batch: 0.261s training loss: 0.4043, training accuracy: 0.8148\n",
      "[Epoch 0][Batch 425][Samples 13632] time/batch: 0.265s training loss: 0.4040, training accuracy: 0.8149\n",
      "[Epoch 0][Batch 426][Samples 13664] time/batch: 0.262s training loss: 0.4040, training accuracy: 0.8147\n",
      "[Epoch 0][Batch 427][Samples 13696] time/batch: 0.259s training loss: 0.4037, training accuracy: 0.8149\n",
      "[Epoch 0][Batch 428][Samples 13728] time/batch: 0.268s training loss: 0.4037, training accuracy: 0.8150\n",
      "[Epoch 0][Batch 429][Samples 13760] time/batch: 0.261s training loss: 0.4033, training accuracy: 0.8153\n",
      "[Epoch 0][Batch 430][Samples 13792] time/batch: 0.276s training loss: 0.4032, training accuracy: 0.8154\n",
      "[Epoch 0][Batch 431][Samples 13824] time/batch: 0.269s training loss: 0.4031, training accuracy: 0.8155\n",
      "[Epoch 0][Batch 432][Samples 13856] time/batch: 0.272s training loss: 0.4033, training accuracy: 0.8152\n",
      "[Epoch 0][Batch 433][Samples 13888] time/batch: 0.273s training loss: 0.4030, training accuracy: 0.8154\n",
      "[Epoch 0][Batch 434][Samples 13920] time/batch: 0.261s training loss: 0.4027, training accuracy: 0.8154\n",
      "[Epoch 0][Batch 435][Samples 13952] time/batch: 0.265s training loss: 0.4031, training accuracy: 0.8152\n",
      "[Epoch 0][Batch 436][Samples 13984] time/batch: 0.261s training loss: 0.4028, training accuracy: 0.8154\n",
      "[Epoch 0][Batch 437][Samples 14016] time/batch: 0.278s training loss: 0.4023, training accuracy: 0.8156\n",
      "[Epoch 0][Batch 438][Samples 14048] time/batch: 0.272s training loss: 0.4021, training accuracy: 0.8157\n",
      "[Epoch 0][Batch 439][Samples 14080] time/batch: 0.263s training loss: 0.4018, training accuracy: 0.8159\n",
      "[Epoch 0][Batch 440][Samples 14112] time/batch: 0.264s training loss: 0.4015, training accuracy: 0.8161\n",
      "[Epoch 0][Batch 441][Samples 14144] time/batch: 0.261s training loss: 0.4012, training accuracy: 0.8162\n",
      "[Epoch 0][Batch 442][Samples 14176] time/batch: 0.260s training loss: 0.4010, training accuracy: 0.8163\n",
      "[Epoch 0][Batch 443][Samples 14208] time/batch: 0.275s training loss: 0.4008, training accuracy: 0.8162\n",
      "[Epoch 0][Batch 444][Samples 14240] time/batch: 0.263s training loss: 0.4007, training accuracy: 0.8164\n",
      "[Epoch 0][Batch 445][Samples 14272] time/batch: 0.266s training loss: 0.4003, training accuracy: 0.8166\n",
      "[Epoch 0][Batch 446][Samples 14304] time/batch: 0.264s training loss: 0.4000, training accuracy: 0.8168\n",
      "[Epoch 0][Batch 447][Samples 14336] time/batch: 0.262s training loss: 0.3998, training accuracy: 0.8170\n",
      "[Epoch 0][Batch 448][Samples 14368] time/batch: 0.267s training loss: 0.3994, training accuracy: 0.8171\n",
      "[Epoch 0][Batch 449][Samples 14400] time/batch: 0.261s training loss: 0.3992, training accuracy: 0.8172\n",
      "[Epoch 0][Batch 450][Samples 14432] time/batch: 0.273s training loss: 0.3991, training accuracy: 0.8171\n",
      "[Epoch 0][Batch 451][Samples 14464] time/batch: 0.272s training loss: 0.3986, training accuracy: 0.8174\n",
      "[Epoch 0][Batch 452][Samples 14496] time/batch: 0.270s training loss: 0.3985, training accuracy: 0.8174\n",
      "[Epoch 0][Batch 453][Samples 14528] time/batch: 0.266s training loss: 0.3980, training accuracy: 0.8177\n",
      "[Epoch 0][Batch 454][Samples 14560] time/batch: 0.261s training loss: 0.3979, training accuracy: 0.8177\n",
      "[Epoch 0][Batch 455][Samples 14592] time/batch: 0.270s training loss: 0.3976, training accuracy: 0.8177\n",
      "[Epoch 0][Batch 456][Samples 14624] time/batch: 0.266s training loss: 0.3975, training accuracy: 0.8178\n",
      "[Epoch 0][Batch 457][Samples 14656] time/batch: 0.267s training loss: 0.3977, training accuracy: 0.8178\n",
      "[Epoch 0][Batch 458][Samples 14688] time/batch: 0.271s training loss: 0.3973, training accuracy: 0.8180\n",
      "[Epoch 0][Batch 459][Samples 14720] time/batch: 0.269s training loss: 0.3971, training accuracy: 0.8181\n",
      "[Epoch 0][Batch 460][Samples 14752] time/batch: 0.273s training loss: 0.3968, training accuracy: 0.8184\n",
      "[Epoch 0][Batch 461][Samples 14784] time/batch: 0.262s training loss: 0.3963, training accuracy: 0.8186\n",
      "[Epoch 0][Batch 462][Samples 14816] time/batch: 0.267s training loss: 0.3959, training accuracy: 0.8188\n",
      "[Epoch 0][Batch 463][Samples 14848] time/batch: 0.263s training loss: 0.3956, training accuracy: 0.8188\n",
      "[Epoch 0][Batch 464][Samples 14880] time/batch: 0.272s training loss: 0.3953, training accuracy: 0.8190\n",
      "[Epoch 0][Batch 465][Samples 14912] time/batch: 0.264s training loss: 0.3955, training accuracy: 0.8189\n",
      "[Epoch 0][Batch 466][Samples 14944] time/batch: 0.262s training loss: 0.3950, training accuracy: 0.8193\n",
      "[Epoch 0][Batch 467][Samples 14976] time/batch: 0.270s training loss: 0.3952, training accuracy: 0.8192\n",
      "[Epoch 0][Batch 468][Samples 15008] time/batch: 0.269s training loss: 0.3949, training accuracy: 0.8194\n",
      "[Epoch 0][Batch 469][Samples 15040] time/batch: 0.261s training loss: 0.3946, training accuracy: 0.8196\n",
      "[Epoch 0][Batch 470][Samples 15072] time/batch: 0.265s training loss: 0.3943, training accuracy: 0.8197\n",
      "[Epoch 0][Batch 471][Samples 15104] time/batch: 0.270s training loss: 0.3938, training accuracy: 0.8200\n",
      "[Epoch 0][Batch 472][Samples 15136] time/batch: 0.272s training loss: 0.3936, training accuracy: 0.8201\n",
      "[Epoch 0][Batch 473][Samples 15168] time/batch: 0.265s training loss: 0.3937, training accuracy: 0.8201\n",
      "[Epoch 0][Batch 474][Samples 15200] time/batch: 0.262s training loss: 0.3938, training accuracy: 0.8201\n",
      "[Epoch 0][Batch 475][Samples 15232] time/batch: 0.269s training loss: 0.3934, training accuracy: 0.8204\n",
      "[Epoch 0][Batch 476][Samples 15264] time/batch: 0.262s training loss: 0.3932, training accuracy: 0.8204\n",
      "[Epoch 0][Batch 477][Samples 15296] time/batch: 0.270s training loss: 0.3932, training accuracy: 0.8205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 478][Samples 15328] time/batch: 0.259s training loss: 0.3927, training accuracy: 0.8208\n",
      "[Epoch 0][Batch 479][Samples 15360] time/batch: 0.266s training loss: 0.3924, training accuracy: 0.8208\n",
      "[Epoch 0][Batch 480][Samples 15392] time/batch: 0.272s training loss: 0.3923, training accuracy: 0.8209\n",
      "[Epoch 0][Batch 481][Samples 15424] time/batch: 0.263s training loss: 0.3926, training accuracy: 0.8207\n",
      "[Epoch 0][Batch 482][Samples 15456] time/batch: 0.263s training loss: 0.3922, training accuracy: 0.8210\n",
      "[Epoch 0][Batch 483][Samples 15488] time/batch: 0.269s training loss: 0.3917, training accuracy: 0.8213\n",
      "[Epoch 0][Batch 484][Samples 15520] time/batch: 0.264s training loss: 0.3917, training accuracy: 0.8213\n",
      "[Epoch 0][Batch 485][Samples 15552] time/batch: 0.272s training loss: 0.3912, training accuracy: 0.8216\n",
      "[Epoch 0][Batch 486][Samples 15584] time/batch: 0.271s training loss: 0.3910, training accuracy: 0.8215\n",
      "[Epoch 0][Batch 487][Samples 15616] time/batch: 0.274s training loss: 0.3908, training accuracy: 0.8218\n",
      "[Epoch 0][Batch 488][Samples 15648] time/batch: 0.271s training loss: 0.3905, training accuracy: 0.8219\n",
      "[Epoch 0][Batch 489][Samples 15680] time/batch: 0.275s training loss: 0.3901, training accuracy: 0.8221\n",
      "[Epoch 0][Batch 490][Samples 15712] time/batch: 0.263s training loss: 0.3898, training accuracy: 0.8222\n",
      "[Epoch 0][Batch 491][Samples 15744] time/batch: 0.260s training loss: 0.3895, training accuracy: 0.8223\n",
      "[Epoch 0][Batch 492][Samples 15776] time/batch: 0.272s training loss: 0.3894, training accuracy: 0.8225\n",
      "[Epoch 0][Batch 493][Samples 15808] time/batch: 0.261s training loss: 0.3892, training accuracy: 0.8226\n",
      "[Epoch 0][Batch 494][Samples 15840] time/batch: 0.264s training loss: 0.3895, training accuracy: 0.8224\n",
      "[Epoch 0][Batch 495][Samples 15872] time/batch: 0.264s training loss: 0.3891, training accuracy: 0.8226\n",
      "[Epoch 0][Batch 496][Samples 15904] time/batch: 0.271s training loss: 0.3888, training accuracy: 0.8228\n",
      "[Epoch 0][Batch 497][Samples 15936] time/batch: 0.277s training loss: 0.3886, training accuracy: 0.8229\n",
      "[Epoch 0][Batch 498][Samples 15968] time/batch: 0.266s training loss: 0.3889, training accuracy: 0.8226\n",
      "[Epoch 0][Batch 499][Samples 16000] time/batch: 0.266s training loss: 0.3886, training accuracy: 0.8228\n",
      "[Epoch 0][Batch 500][Samples 16032] time/batch: 0.275s training loss: 0.3885, training accuracy: 0.8228\n",
      "[Epoch 0][Batch 501][Samples 16064] time/batch: 0.270s training loss: 0.3881, training accuracy: 0.8230\n",
      "[Epoch 0][Batch 502][Samples 16096] time/batch: 0.262s training loss: 0.3879, training accuracy: 0.8229\n",
      "[Epoch 0][Batch 503][Samples 16128] time/batch: 0.267s training loss: 0.3879, training accuracy: 0.8230\n",
      "[Epoch 0][Batch 504][Samples 16160] time/batch: 0.262s training loss: 0.3878, training accuracy: 0.8231\n",
      "[Epoch 0][Batch 505][Samples 16192] time/batch: 0.265s training loss: 0.3877, training accuracy: 0.8231\n",
      "[Epoch 0][Batch 506][Samples 16224] time/batch: 0.262s training loss: 0.3875, training accuracy: 0.8232\n",
      "[Epoch 0][Batch 507][Samples 16256] time/batch: 0.267s training loss: 0.3872, training accuracy: 0.8233\n",
      "[Epoch 0][Batch 508][Samples 16288] time/batch: 0.263s training loss: 0.3869, training accuracy: 0.8236\n",
      "[Epoch 0][Batch 509][Samples 16320] time/batch: 0.269s training loss: 0.3867, training accuracy: 0.8236\n",
      "[Epoch 0][Batch 510][Samples 16352] time/batch: 0.261s training loss: 0.3861, training accuracy: 0.8238\n",
      "[Epoch 0][Batch 511][Samples 16384] time/batch: 0.262s training loss: 0.3857, training accuracy: 0.8240\n",
      "[Epoch 0][Batch 512][Samples 16416] time/batch: 0.270s training loss: 0.3860, training accuracy: 0.8238\n",
      "[Epoch 0][Batch 513][Samples 16448] time/batch: 0.268s training loss: 0.3861, training accuracy: 0.8238\n",
      "[Epoch 0][Batch 514][Samples 16480] time/batch: 0.265s training loss: 0.3856, training accuracy: 0.8241\n",
      "[Epoch 0][Batch 515][Samples 16512] time/batch: 0.261s training loss: 0.3857, training accuracy: 0.8241\n",
      "[Epoch 0][Batch 516][Samples 16544] time/batch: 0.269s training loss: 0.3855, training accuracy: 0.8241\n",
      "[Epoch 0][Batch 517][Samples 16576] time/batch: 0.259s training loss: 0.3852, training accuracy: 0.8243\n",
      "[Epoch 0][Batch 518][Samples 16608] time/batch: 0.266s training loss: 0.3852, training accuracy: 0.8244\n",
      "[Epoch 0][Batch 519][Samples 16640] time/batch: 0.260s training loss: 0.3852, training accuracy: 0.8244\n",
      "[Epoch 0][Batch 520][Samples 16672] time/batch: 0.267s training loss: 0.3850, training accuracy: 0.8245\n",
      "[Epoch 0][Batch 521][Samples 16704] time/batch: 0.263s training loss: 0.3850, training accuracy: 0.8247\n",
      "[Epoch 0][Batch 522][Samples 16736] time/batch: 0.268s training loss: 0.3845, training accuracy: 0.8250\n",
      "[Epoch 0][Batch 523][Samples 16768] time/batch: 0.268s training loss: 0.3841, training accuracy: 0.8251\n",
      "[Epoch 0][Batch 524][Samples 16800] time/batch: 0.261s training loss: 0.3841, training accuracy: 0.8252\n",
      "[Epoch 0][Batch 525][Samples 16832] time/batch: 0.264s training loss: 0.3841, training accuracy: 0.8253\n",
      "[Epoch 0][Batch 526][Samples 16864] time/batch: 0.262s training loss: 0.3838, training accuracy: 0.8254\n",
      "[Epoch 0][Batch 527][Samples 16896] time/batch: 0.266s training loss: 0.3835, training accuracy: 0.8256\n",
      "[Epoch 0][Batch 528][Samples 16928] time/batch: 0.261s training loss: 0.3834, training accuracy: 0.8257\n",
      "[Epoch 0][Batch 529][Samples 16960] time/batch: 0.264s training loss: 0.3831, training accuracy: 0.8259\n",
      "[Epoch 0][Batch 530][Samples 16992] time/batch: 0.262s training loss: 0.3826, training accuracy: 0.8262\n",
      "[Epoch 0][Batch 531][Samples 17024] time/batch: 0.266s training loss: 0.3822, training accuracy: 0.8264\n",
      "[Epoch 0][Batch 532][Samples 17056] time/batch: 0.270s training loss: 0.3819, training accuracy: 0.8266\n",
      "[Epoch 0][Batch 533][Samples 17088] time/batch: 0.265s training loss: 0.3819, training accuracy: 0.8267\n",
      "[Epoch 0][Batch 534][Samples 17120] time/batch: 0.261s training loss: 0.3820, training accuracy: 0.8265\n",
      "[Epoch 0][Batch 535][Samples 17152] time/batch: 0.265s training loss: 0.3821, training accuracy: 0.8266\n",
      "[Epoch 0][Batch 536][Samples 17184] time/batch: 0.264s training loss: 0.3820, training accuracy: 0.8268\n",
      "[Epoch 0][Batch 537][Samples 17216] time/batch: 0.269s training loss: 0.3818, training accuracy: 0.8269\n",
      "[Epoch 0][Batch 538][Samples 17248] time/batch: 0.264s training loss: 0.3816, training accuracy: 0.8269\n",
      "[Epoch 0][Batch 539][Samples 17280] time/batch: 0.265s training loss: 0.3814, training accuracy: 0.8271\n",
      "[Epoch 0][Batch 540][Samples 17312] time/batch: 0.266s training loss: 0.3814, training accuracy: 0.8271\n",
      "[Epoch 0][Batch 541][Samples 17344] time/batch: 0.271s training loss: 0.3814, training accuracy: 0.8271\n",
      "[Epoch 0][Batch 542][Samples 17376] time/batch: 0.275s training loss: 0.3813, training accuracy: 0.8271\n",
      "[Epoch 0][Batch 543][Samples 17408] time/batch: 0.272s training loss: 0.3811, training accuracy: 0.8272\n",
      "[Epoch 0][Batch 544][Samples 17440] time/batch: 0.271s training loss: 0.3807, training accuracy: 0.8275\n",
      "[Epoch 0][Batch 545][Samples 17472] time/batch: 0.278s training loss: 0.3805, training accuracy: 0.8274\n",
      "[Epoch 0][Batch 546][Samples 17504] time/batch: 0.272s training loss: 0.3810, training accuracy: 0.8273\n",
      "[Epoch 0][Batch 547][Samples 17536] time/batch: 0.277s training loss: 0.3806, training accuracy: 0.8274\n",
      "[Epoch 0][Batch 548][Samples 17568] time/batch: 0.265s training loss: 0.3806, training accuracy: 0.8275\n",
      "[Epoch 0][Batch 549][Samples 17600] time/batch: 0.261s training loss: 0.3805, training accuracy: 0.8276\n",
      "[Epoch 0][Batch 550][Samples 17632] time/batch: 0.265s training loss: 0.3802, training accuracy: 0.8277\n",
      "[Epoch 0][Batch 551][Samples 17664] time/batch: 0.262s training loss: 0.3798, training accuracy: 0.8280\n",
      "[Epoch 0][Batch 552][Samples 17696] time/batch: 0.276s training loss: 0.3797, training accuracy: 0.8280\n",
      "[Epoch 0][Batch 553][Samples 17728] time/batch: 0.262s training loss: 0.3796, training accuracy: 0.8281\n",
      "[Epoch 0][Batch 554][Samples 17760] time/batch: 0.262s training loss: 0.3793, training accuracy: 0.8283\n",
      "[Epoch 0][Batch 555][Samples 17792] time/batch: 0.273s training loss: 0.3794, training accuracy: 0.8282\n",
      "[Epoch 0][Batch 556][Samples 17824] time/batch: 0.261s training loss: 0.3791, training accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 557][Samples 17856] time/batch: 0.271s training loss: 0.3790, training accuracy: 0.8284\n",
      "[Epoch 0][Batch 558][Samples 17888] time/batch: 0.260s training loss: 0.3787, training accuracy: 0.8286\n",
      "[Epoch 0][Batch 559][Samples 17920] time/batch: 0.274s training loss: 0.3786, training accuracy: 0.8287\n",
      "[Epoch 0][Batch 560][Samples 17952] time/batch: 0.263s training loss: 0.3784, training accuracy: 0.8288\n",
      "[Epoch 0][Batch 561][Samples 17984] time/batch: 0.280s training loss: 0.3780, training accuracy: 0.8290\n",
      "[Epoch 0][Batch 562][Samples 18016] time/batch: 0.276s training loss: 0.3777, training accuracy: 0.8292\n",
      "[Epoch 0][Batch 563][Samples 18048] time/batch: 0.261s training loss: 0.3776, training accuracy: 0.8292\n",
      "[Epoch 0][Batch 564][Samples 18080] time/batch: 0.270s training loss: 0.3775, training accuracy: 0.8291\n",
      "[Epoch 0][Batch 565][Samples 18112] time/batch: 0.261s training loss: 0.3774, training accuracy: 0.8290\n",
      "[Epoch 0][Batch 566][Samples 18144] time/batch: 0.268s training loss: 0.3779, training accuracy: 0.8289\n",
      "[Epoch 0][Batch 567][Samples 18176] time/batch: 0.272s training loss: 0.3778, training accuracy: 0.8289\n",
      "[Epoch 0][Batch 568][Samples 18208] time/batch: 0.279s training loss: 0.3778, training accuracy: 0.8289\n",
      "[Epoch 0][Batch 569][Samples 18240] time/batch: 0.273s training loss: 0.3777, training accuracy: 0.8291\n",
      "[Epoch 0][Batch 570][Samples 18272] time/batch: 0.262s training loss: 0.3774, training accuracy: 0.8292\n",
      "[Epoch 0][Batch 571][Samples 18304] time/batch: 0.269s training loss: 0.3771, training accuracy: 0.8293\n",
      "[Epoch 0][Batch 572][Samples 18336] time/batch: 0.267s training loss: 0.3767, training accuracy: 0.8296\n",
      "[Epoch 0][Batch 573][Samples 18368] time/batch: 0.261s training loss: 0.3764, training accuracy: 0.8298\n",
      "[Epoch 0][Batch 574][Samples 18400] time/batch: 0.270s training loss: 0.3763, training accuracy: 0.8297\n",
      "[Epoch 0][Batch 575][Samples 18432] time/batch: 0.261s training loss: 0.3765, training accuracy: 0.8296\n",
      "[Epoch 0][Batch 576][Samples 18464] time/batch: 0.272s training loss: 0.3764, training accuracy: 0.8296\n",
      "[Epoch 0][Batch 577][Samples 18496] time/batch: 0.265s training loss: 0.3762, training accuracy: 0.8297\n",
      "[Epoch 0][Batch 578][Samples 18528] time/batch: 0.265s training loss: 0.3760, training accuracy: 0.8298\n",
      "[Epoch 0][Batch 579][Samples 18560] time/batch: 0.268s training loss: 0.3755, training accuracy: 0.8300\n",
      "[Epoch 0][Batch 580][Samples 18592] time/batch: 0.273s training loss: 0.3751, training accuracy: 0.8301\n",
      "[Epoch 0][Batch 581][Samples 18624] time/batch: 0.281s training loss: 0.3747, training accuracy: 0.8303\n",
      "[Epoch 0][Batch 582][Samples 18656] time/batch: 0.277s training loss: 0.3746, training accuracy: 0.8303\n",
      "[Epoch 0][Batch 583][Samples 18688] time/batch: 0.270s training loss: 0.3744, training accuracy: 0.8304\n",
      "[Epoch 0][Batch 584][Samples 18720] time/batch: 0.266s training loss: 0.3740, training accuracy: 0.8307\n",
      "[Epoch 0][Batch 585][Samples 18752] time/batch: 0.264s training loss: 0.3740, training accuracy: 0.8308\n",
      "[Epoch 0][Batch 586][Samples 18784] time/batch: 0.268s training loss: 0.3737, training accuracy: 0.8310\n",
      "[Epoch 0][Batch 587][Samples 18816] time/batch: 0.261s training loss: 0.3738, training accuracy: 0.8310\n",
      "[Epoch 0][Batch 588][Samples 18848] time/batch: 0.264s training loss: 0.3734, training accuracy: 0.8313\n",
      "[Epoch 0][Batch 589][Samples 18880] time/batch: 0.268s training loss: 0.3731, training accuracy: 0.8315\n",
      "[Epoch 0][Batch 590][Samples 18912] time/batch: 0.261s training loss: 0.3730, training accuracy: 0.8315\n",
      "[Epoch 0][Batch 591][Samples 18944] time/batch: 0.267s training loss: 0.3726, training accuracy: 0.8318\n",
      "[Epoch 0][Batch 592][Samples 18976] time/batch: 0.262s training loss: 0.3725, training accuracy: 0.8318\n",
      "[Epoch 0][Batch 593][Samples 19008] time/batch: 0.262s training loss: 0.3720, training accuracy: 0.8321\n",
      "[Epoch 0][Batch 594][Samples 19040] time/batch: 0.265s training loss: 0.3721, training accuracy: 0.8321\n",
      "[Epoch 0][Batch 595][Samples 19072] time/batch: 0.270s training loss: 0.3717, training accuracy: 0.8324\n",
      "[Epoch 0][Batch 596][Samples 19104] time/batch: 0.274s training loss: 0.3719, training accuracy: 0.8323\n",
      "[Epoch 0][Batch 597][Samples 19136] time/batch: 0.264s training loss: 0.3722, training accuracy: 0.8323\n",
      "[Epoch 0][Batch 598][Samples 19168] time/batch: 0.264s training loss: 0.3719, training accuracy: 0.8324\n",
      "[Epoch 0][Batch 599][Samples 19200] time/batch: 0.260s training loss: 0.3717, training accuracy: 0.8325\n",
      "[Epoch 0][Batch 600][Samples 19232] time/batch: 0.267s training loss: 0.3716, training accuracy: 0.8326\n",
      "[Epoch 0][Batch 601][Samples 19264] time/batch: 0.266s training loss: 0.3714, training accuracy: 0.8328\n",
      "[Epoch 0][Batch 602][Samples 19296] time/batch: 0.262s training loss: 0.3714, training accuracy: 0.8328\n",
      "[Epoch 0][Batch 603][Samples 19328] time/batch: 0.267s training loss: 0.3711, training accuracy: 0.8330\n",
      "[Epoch 0][Batch 604][Samples 19360] time/batch: 0.262s training loss: 0.3713, training accuracy: 0.8330\n",
      "[Epoch 0][Batch 605][Samples 19392] time/batch: 0.277s training loss: 0.3714, training accuracy: 0.8330\n",
      "[Epoch 0][Batch 606][Samples 19424] time/batch: 0.266s training loss: 0.3713, training accuracy: 0.8331\n",
      "[Epoch 0][Batch 607][Samples 19456] time/batch: 0.262s training loss: 0.3713, training accuracy: 0.8331\n",
      "[Epoch 0][Batch 608][Samples 19488] time/batch: 0.276s training loss: 0.3711, training accuracy: 0.8332\n",
      "[Epoch 0][Batch 609][Samples 19520] time/batch: 0.261s training loss: 0.3713, training accuracy: 0.8331\n",
      "[Epoch 0][Batch 610][Samples 19552] time/batch: 0.280s training loss: 0.3715, training accuracy: 0.8329\n",
      "[Epoch 0][Batch 611][Samples 19584] time/batch: 0.268s training loss: 0.3712, training accuracy: 0.8330\n",
      "[Epoch 0][Batch 612][Samples 19616] time/batch: 0.262s training loss: 0.3711, training accuracy: 0.8331\n",
      "[Epoch 0][Batch 613][Samples 19648] time/batch: 0.266s training loss: 0.3708, training accuracy: 0.8333\n",
      "[Epoch 0][Batch 614][Samples 19680] time/batch: 0.268s training loss: 0.3706, training accuracy: 0.8334\n",
      "[Epoch 0][Batch 615][Samples 19712] time/batch: 0.267s training loss: 0.3704, training accuracy: 0.8335\n",
      "[Epoch 0][Batch 616][Samples 19744] time/batch: 0.263s training loss: 0.3701, training accuracy: 0.8337\n",
      "[Epoch 0][Batch 617][Samples 19776] time/batch: 0.268s training loss: 0.3699, training accuracy: 0.8338\n",
      "[Epoch 0][Batch 618][Samples 19808] time/batch: 0.264s training loss: 0.3697, training accuracy: 0.8339\n",
      "[Epoch 0][Batch 619][Samples 19840] time/batch: 0.266s training loss: 0.3697, training accuracy: 0.8339\n",
      "[Epoch 0][Batch 620][Samples 19872] time/batch: 0.264s training loss: 0.3696, training accuracy: 0.8340\n",
      "[Epoch 0][Batch 621][Samples 19904] time/batch: 0.270s training loss: 0.3695, training accuracy: 0.8340\n",
      "[Epoch 0][Batch 622][Samples 19936] time/batch: 0.262s training loss: 0.3693, training accuracy: 0.8341\n",
      "[Epoch 0][Batch 623][Samples 19968] time/batch: 0.279s training loss: 0.3696, training accuracy: 0.8340\n",
      "[Epoch 0][Batch 624][Samples 20000] time/batch: 0.273s training loss: 0.3694, training accuracy: 0.8341\n",
      "[Epoch 0][Batch 625][Samples 20032] time/batch: 0.276s training loss: 0.3691, training accuracy: 0.8343\n",
      "[Epoch 0][Batch 626][Samples 20064] time/batch: 0.266s training loss: 0.3688, training accuracy: 0.8345\n",
      "[Epoch 0][Batch 627][Samples 20096] time/batch: 0.260s training loss: 0.3689, training accuracy: 0.8345\n",
      "[Epoch 0][Batch 628][Samples 20128] time/batch: 0.267s training loss: 0.3690, training accuracy: 0.8345\n",
      "[Epoch 0][Batch 629][Samples 20160] time/batch: 0.261s training loss: 0.3690, training accuracy: 0.8346\n",
      "[Epoch 0][Batch 630][Samples 20192] time/batch: 0.261s training loss: 0.3687, training accuracy: 0.8348\n",
      "[Epoch 0][Batch 631][Samples 20224] time/batch: 0.266s training loss: 0.3685, training accuracy: 0.8349\n",
      "[Epoch 0][Batch 632][Samples 20256] time/batch: 0.262s training loss: 0.3685, training accuracy: 0.8349\n",
      "[Epoch 0][Batch 633][Samples 20288] time/batch: 0.267s training loss: 0.3685, training accuracy: 0.8348\n",
      "[Epoch 0][Batch 634][Samples 20320] time/batch: 0.262s training loss: 0.3685, training accuracy: 0.8348\n",
      "[Epoch 0][Batch 635][Samples 20352] time/batch: 0.271s training loss: 0.3684, training accuracy: 0.8349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 636][Samples 20384] time/batch: 0.262s training loss: 0.3683, training accuracy: 0.8350\n",
      "[Epoch 0][Batch 637][Samples 20416] time/batch: 0.273s training loss: 0.3681, training accuracy: 0.8351\n",
      "[Epoch 0][Batch 638][Samples 20448] time/batch: 0.264s training loss: 0.3678, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 639][Samples 20480] time/batch: 0.263s training loss: 0.3680, training accuracy: 0.8352\n",
      "[Epoch 0][Batch 640][Samples 20512] time/batch: 0.266s training loss: 0.3678, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 641][Samples 20544] time/batch: 0.265s training loss: 0.3677, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 642][Samples 20576] time/batch: 0.269s training loss: 0.3677, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 643][Samples 20608] time/batch: 0.263s training loss: 0.3676, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 644][Samples 20640] time/batch: 0.263s training loss: 0.3676, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 645][Samples 20672] time/batch: 0.266s training loss: 0.3675, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 646][Samples 20704] time/batch: 0.265s training loss: 0.3672, training accuracy: 0.8356\n",
      "[Epoch 0][Batch 647][Samples 20736] time/batch: 0.268s training loss: 0.3675, training accuracy: 0.8352\n",
      "[Epoch 0][Batch 648][Samples 20768] time/batch: 0.261s training loss: 0.3677, training accuracy: 0.8352\n",
      "[Epoch 0][Batch 649][Samples 20800] time/batch: 0.265s training loss: 0.3677, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 650][Samples 20832] time/batch: 0.261s training loss: 0.3675, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 651][Samples 20864] time/batch: 0.268s training loss: 0.3673, training accuracy: 0.8355\n",
      "[Epoch 0][Batch 652][Samples 20896] time/batch: 0.261s training loss: 0.3673, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 653][Samples 20928] time/batch: 0.266s training loss: 0.3671, training accuracy: 0.8355\n",
      "[Epoch 0][Batch 654][Samples 20960] time/batch: 0.262s training loss: 0.3670, training accuracy: 0.8355\n",
      "[Epoch 0][Batch 655][Samples 20992] time/batch: 0.266s training loss: 0.3667, training accuracy: 0.8356\n",
      "[Epoch 0][Batch 656][Samples 21024] time/batch: 0.265s training loss: 0.3667, training accuracy: 0.8357\n",
      "[Epoch 0][Batch 657][Samples 21056] time/batch: 0.261s training loss: 0.3665, training accuracy: 0.8358\n",
      "[Epoch 0][Batch 658][Samples 21088] time/batch: 0.269s training loss: 0.3662, training accuracy: 0.8360\n",
      "[Epoch 0][Batch 659][Samples 21120] time/batch: 0.261s training loss: 0.3660, training accuracy: 0.8361\n",
      "[Epoch 0][Batch 660][Samples 21152] time/batch: 0.268s training loss: 0.3659, training accuracy: 0.8362\n",
      "[Epoch 0][Batch 661][Samples 21184] time/batch: 0.261s training loss: 0.3658, training accuracy: 0.8362\n",
      "[Epoch 0][Batch 662][Samples 21216] time/batch: 0.273s training loss: 0.3657, training accuracy: 0.8362\n",
      "[Epoch 0][Batch 663][Samples 21248] time/batch: 0.264s training loss: 0.3654, training accuracy: 0.8364\n",
      "[Epoch 0][Batch 664][Samples 21280] time/batch: 0.271s training loss: 0.3656, training accuracy: 0.8362\n",
      "[Epoch 0][Batch 665][Samples 21312] time/batch: 0.268s training loss: 0.3656, training accuracy: 0.8363\n",
      "[Epoch 0][Batch 666][Samples 21344] time/batch: 0.266s training loss: 0.3655, training accuracy: 0.8363\n",
      "[Epoch 0][Batch 667][Samples 21376] time/batch: 0.267s training loss: 0.3655, training accuracy: 0.8364\n",
      "[Epoch 0][Batch 668][Samples 21408] time/batch: 0.262s training loss: 0.3655, training accuracy: 0.8364\n",
      "[Epoch 0][Batch 669][Samples 21440] time/batch: 0.270s training loss: 0.3654, training accuracy: 0.8364\n",
      "[Epoch 0][Batch 670][Samples 21472] time/batch: 0.264s training loss: 0.3651, training accuracy: 0.8366\n",
      "[Epoch 0][Batch 671][Samples 21504] time/batch: 0.264s training loss: 0.3649, training accuracy: 0.8367\n",
      "[Epoch 0][Batch 672][Samples 21536] time/batch: 0.274s training loss: 0.3647, training accuracy: 0.8368\n",
      "[Epoch 0][Batch 673][Samples 21568] time/batch: 0.266s training loss: 0.3645, training accuracy: 0.8369\n",
      "[Epoch 0][Batch 674][Samples 21600] time/batch: 0.269s training loss: 0.3642, training accuracy: 0.8371\n",
      "[Epoch 0][Batch 675][Samples 21632] time/batch: 0.267s training loss: 0.3644, training accuracy: 0.8370\n",
      "[Epoch 0][Batch 676][Samples 21664] time/batch: 0.261s training loss: 0.3642, training accuracy: 0.8371\n",
      "[Epoch 0][Batch 677][Samples 21696] time/batch: 0.266s training loss: 0.3640, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 678][Samples 21728] time/batch: 0.263s training loss: 0.3639, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 679][Samples 21760] time/batch: 0.270s training loss: 0.3638, training accuracy: 0.8373\n",
      "[Epoch 0][Batch 680][Samples 21792] time/batch: 0.261s training loss: 0.3638, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 681][Samples 21824] time/batch: 0.264s training loss: 0.3636, training accuracy: 0.8373\n",
      "[Epoch 0][Batch 682][Samples 21856] time/batch: 0.263s training loss: 0.3636, training accuracy: 0.8373\n",
      "[Epoch 0][Batch 683][Samples 21888] time/batch: 0.268s training loss: 0.3634, training accuracy: 0.8375\n",
      "[Epoch 0][Batch 684][Samples 21920] time/batch: 0.266s training loss: 0.3633, training accuracy: 0.8375\n",
      "[Epoch 0][Batch 685][Samples 21952] time/batch: 0.270s training loss: 0.3633, training accuracy: 0.8376\n",
      "[Epoch 0][Batch 686][Samples 21984] time/batch: 0.265s training loss: 0.3632, training accuracy: 0.8375\n",
      "[Epoch 0][Batch 687][Samples 22016] time/batch: 0.265s training loss: 0.3632, training accuracy: 0.8376\n",
      "[Epoch 0][Batch 688][Samples 22048] time/batch: 0.274s training loss: 0.3630, training accuracy: 0.8376\n",
      "[Epoch 0][Batch 689][Samples 22080] time/batch: 0.275s training loss: 0.3630, training accuracy: 0.8376\n",
      "[Epoch 0][Batch 690][Samples 22112] time/batch: 0.269s training loss: 0.3630, training accuracy: 0.8377\n",
      "[Epoch 0][Batch 691][Samples 22144] time/batch: 0.266s training loss: 0.3628, training accuracy: 0.8377\n",
      "[Epoch 0][Batch 692][Samples 22176] time/batch: 0.264s training loss: 0.3631, training accuracy: 0.8377\n",
      "[Epoch 0][Batch 693][Samples 22208] time/batch: 0.266s training loss: 0.3631, training accuracy: 0.8377\n",
      "[Epoch 0][Batch 694][Samples 22240] time/batch: 0.267s training loss: 0.3629, training accuracy: 0.8377\n",
      "[Epoch 0][Batch 695][Samples 22272] time/batch: 0.261s training loss: 0.3630, training accuracy: 0.8376\n",
      "[Epoch 0][Batch 696][Samples 22304] time/batch: 0.271s training loss: 0.3629, training accuracy: 0.8377\n",
      "[Epoch 0][Batch 697][Samples 22336] time/batch: 0.269s training loss: 0.3625, training accuracy: 0.8379\n",
      "[Epoch 0][Batch 698][Samples 22368] time/batch: 0.267s training loss: 0.3625, training accuracy: 0.8379\n",
      "[Epoch 0][Batch 699][Samples 22400] time/batch: 0.264s training loss: 0.3624, training accuracy: 0.8381\n",
      "[Epoch 0][Batch 700][Samples 22432] time/batch: 0.275s training loss: 0.3622, training accuracy: 0.8382\n",
      "[Epoch 0][Batch 701][Samples 22464] time/batch: 0.273s training loss: 0.3620, training accuracy: 0.8382\n",
      "[Epoch 0][Batch 702][Samples 22496] time/batch: 0.266s training loss: 0.3619, training accuracy: 0.8382\n",
      "[Epoch 0][Batch 703][Samples 22528] time/batch: 0.261s training loss: 0.3618, training accuracy: 0.8382\n",
      "[Epoch 0][Batch 704][Samples 22560] time/batch: 0.262s training loss: 0.3617, training accuracy: 0.8383\n",
      "[Epoch 0][Batch 705][Samples 22592] time/batch: 0.268s training loss: 0.3615, training accuracy: 0.8384\n",
      "[Epoch 0][Batch 706][Samples 22624] time/batch: 0.261s training loss: 0.3614, training accuracy: 0.8384\n",
      "[Epoch 0][Batch 707][Samples 22656] time/batch: 0.266s training loss: 0.3614, training accuracy: 0.8384\n",
      "[Epoch 0][Batch 708][Samples 22688] time/batch: 0.261s training loss: 0.3615, training accuracy: 0.8383\n",
      "[Epoch 0][Batch 709][Samples 22720] time/batch: 0.274s training loss: 0.3612, training accuracy: 0.8386\n",
      "[Epoch 0][Batch 710][Samples 22752] time/batch: 0.265s training loss: 0.3609, training accuracy: 0.8387\n",
      "[Epoch 0][Batch 711][Samples 22784] time/batch: 0.266s training loss: 0.3609, training accuracy: 0.8387\n",
      "[Epoch 0][Batch 712][Samples 22816] time/batch: 0.263s training loss: 0.3607, training accuracy: 0.8388\n",
      "[Epoch 0][Batch 713][Samples 22848] time/batch: 0.271s training loss: 0.3605, training accuracy: 0.8389\n",
      "[Epoch 0][Batch 714][Samples 22880] time/batch: 0.263s training loss: 0.3602, training accuracy: 0.8391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 715][Samples 22912] time/batch: 0.279s training loss: 0.3602, training accuracy: 0.8390\n",
      "[Epoch 0][Batch 716][Samples 22944] time/batch: 0.265s training loss: 0.3602, training accuracy: 0.8390\n",
      "[Epoch 0][Batch 717][Samples 22976] time/batch: 0.261s training loss: 0.3600, training accuracy: 0.8390\n",
      "[Epoch 0][Batch 718][Samples 23008] time/batch: 0.266s training loss: 0.3598, training accuracy: 0.8390\n",
      "[Epoch 0][Batch 719][Samples 23040] time/batch: 0.262s training loss: 0.3597, training accuracy: 0.8391\n",
      "[Epoch 0][Batch 720][Samples 23072] time/batch: 0.271s training loss: 0.3597, training accuracy: 0.8391\n",
      "[Epoch 0][Batch 721][Samples 23104] time/batch: 0.260s training loss: 0.3596, training accuracy: 0.8391\n",
      "[Epoch 0][Batch 722][Samples 23136] time/batch: 0.267s training loss: 0.3595, training accuracy: 0.8391\n",
      "[Epoch 0][Batch 723][Samples 23168] time/batch: 0.265s training loss: 0.3592, training accuracy: 0.8392\n",
      "[Epoch 0][Batch 724][Samples 23200] time/batch: 0.264s training loss: 0.3591, training accuracy: 0.8392\n",
      "[Epoch 0][Batch 725][Samples 23232] time/batch: 0.269s training loss: 0.3590, training accuracy: 0.8393\n",
      "[Epoch 0][Batch 726][Samples 23264] time/batch: 0.274s training loss: 0.3590, training accuracy: 0.8392\n",
      "[Epoch 0][Batch 727][Samples 23296] time/batch: 0.262s training loss: 0.3589, training accuracy: 0.8393\n",
      "[Epoch 0][Batch 728][Samples 23328] time/batch: 0.269s training loss: 0.3586, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 729][Samples 23360] time/batch: 0.263s training loss: 0.3587, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 730][Samples 23392] time/batch: 0.270s training loss: 0.3588, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 731][Samples 23424] time/batch: 0.268s training loss: 0.3588, training accuracy: 0.8392\n",
      "[Epoch 0][Batch 732][Samples 23456] time/batch: 0.271s training loss: 0.3586, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 733][Samples 23488] time/batch: 0.269s training loss: 0.3585, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 734][Samples 23520] time/batch: 0.263s training loss: 0.3585, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 735][Samples 23552] time/batch: 0.268s training loss: 0.3584, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 736][Samples 23584] time/batch: 0.266s training loss: 0.3583, training accuracy: 0.8394\n",
      "[Epoch 0][Batch 737][Samples 23616] time/batch: 0.270s training loss: 0.3581, training accuracy: 0.8395\n",
      "[Epoch 0][Batch 738][Samples 23648] time/batch: 0.266s training loss: 0.3581, training accuracy: 0.8395\n",
      "[Epoch 0][Batch 739][Samples 23680] time/batch: 0.277s training loss: 0.3579, training accuracy: 0.8397\n",
      "[Epoch 0][Batch 740][Samples 23712] time/batch: 0.274s training loss: 0.3580, training accuracy: 0.8396\n",
      "[Epoch 0][Batch 741][Samples 23744] time/batch: 0.268s training loss: 0.3582, training accuracy: 0.8396\n",
      "[Epoch 0][Batch 742][Samples 23776] time/batch: 0.263s training loss: 0.3579, training accuracy: 0.8398\n",
      "[Epoch 0][Batch 743][Samples 23808] time/batch: 0.273s training loss: 0.3578, training accuracy: 0.8399\n",
      "[Epoch 0][Batch 744][Samples 23840] time/batch: 0.265s training loss: 0.3576, training accuracy: 0.8400\n",
      "[Epoch 0][Batch 745][Samples 23872] time/batch: 0.271s training loss: 0.3574, training accuracy: 0.8401\n",
      "[Epoch 0][Batch 746][Samples 23904] time/batch: 0.264s training loss: 0.3573, training accuracy: 0.8401\n",
      "[Epoch 0][Batch 747][Samples 23936] time/batch: 0.263s training loss: 0.3573, training accuracy: 0.8400\n",
      "[Epoch 0][Batch 748][Samples 23968] time/batch: 0.269s training loss: 0.3573, training accuracy: 0.8400\n",
      "[Epoch 0][Batch 749][Samples 24000] time/batch: 0.266s training loss: 0.3575, training accuracy: 0.8400\n",
      "[Epoch 0][Batch 750][Samples 24032] time/batch: 0.271s training loss: 0.3575, training accuracy: 0.8400\n",
      "[Epoch 0][Batch 751][Samples 24064] time/batch: 0.269s training loss: 0.3575, training accuracy: 0.8399\n",
      "[Epoch 0][Batch 752][Samples 24096] time/batch: 0.263s training loss: 0.3574, training accuracy: 0.8398\n",
      "[Epoch 0][Batch 753][Samples 24128] time/batch: 0.271s training loss: 0.3574, training accuracy: 0.8399\n",
      "[Epoch 0][Batch 754][Samples 24160] time/batch: 0.264s training loss: 0.3575, training accuracy: 0.8399\n",
      "[Epoch 0][Batch 755][Samples 24192] time/batch: 0.279s training loss: 0.3573, training accuracy: 0.8400\n",
      "[Epoch 0][Batch 756][Samples 24224] time/batch: 0.263s training loss: 0.3571, training accuracy: 0.8400\n",
      "[Epoch 0][Batch 757][Samples 24256] time/batch: 0.272s training loss: 0.3569, training accuracy: 0.8402\n",
      "[Epoch 0][Batch 758][Samples 24288] time/batch: 0.265s training loss: 0.3568, training accuracy: 0.8402\n",
      "[Epoch 0][Batch 759][Samples 24320] time/batch: 0.268s training loss: 0.3567, training accuracy: 0.8401\n",
      "[Epoch 0][Batch 760][Samples 24352] time/batch: 0.264s training loss: 0.3565, training accuracy: 0.8402\n",
      "[Epoch 0][Batch 761][Samples 24384] time/batch: 0.272s training loss: 0.3565, training accuracy: 0.8402\n",
      "[Epoch 0][Batch 762][Samples 24416] time/batch: 0.270s training loss: 0.3563, training accuracy: 0.8403\n",
      "[Epoch 0][Batch 763][Samples 24448] time/batch: 0.263s training loss: 0.3561, training accuracy: 0.8404\n",
      "[Epoch 0][Batch 764][Samples 24480] time/batch: 0.270s training loss: 0.3558, training accuracy: 0.8406\n",
      "[Epoch 0][Batch 765][Samples 24512] time/batch: 0.267s training loss: 0.3556, training accuracy: 0.8406\n",
      "[Epoch 0][Batch 766][Samples 24544] time/batch: 0.264s training loss: 0.3554, training accuracy: 0.8407\n",
      "[Epoch 0][Batch 767][Samples 24576] time/batch: 0.272s training loss: 0.3551, training accuracy: 0.8409\n",
      "[Epoch 0][Batch 768][Samples 24608] time/batch: 0.268s training loss: 0.3551, training accuracy: 0.8409\n",
      "[Epoch 0][Batch 769][Samples 24640] time/batch: 0.263s training loss: 0.3552, training accuracy: 0.8409\n",
      "[Epoch 0][Batch 770][Samples 24672] time/batch: 0.269s training loss: 0.3555, training accuracy: 0.8407\n",
      "[Epoch 0][Batch 771][Samples 24704] time/batch: 0.262s training loss: 0.3555, training accuracy: 0.8408\n",
      "[Epoch 0][Batch 772][Samples 24736] time/batch: 0.269s training loss: 0.3555, training accuracy: 0.8407\n",
      "[Epoch 0][Batch 773][Samples 24768] time/batch: 0.264s training loss: 0.3554, training accuracy: 0.8407\n",
      "[Epoch 0][Batch 774][Samples 24800] time/batch: 0.273s training loss: 0.3555, training accuracy: 0.8406\n",
      "[Epoch 0][Batch 775][Samples 24832] time/batch: 0.277s training loss: 0.3554, training accuracy: 0.8407\n",
      "[Epoch 0][Batch 776][Samples 24864] time/batch: 0.278s training loss: 0.3551, training accuracy: 0.8408\n",
      "[Epoch 0][Batch 777][Samples 24896] time/batch: 0.274s training loss: 0.3548, training accuracy: 0.8410\n",
      "[Epoch 0][Batch 778][Samples 24928] time/batch: 0.278s training loss: 0.3548, training accuracy: 0.8411\n",
      "[Epoch 0][Batch 779][Samples 24960] time/batch: 0.269s training loss: 0.3547, training accuracy: 0.8411\n",
      "[Epoch 0][Batch 780][Samples 24992] time/batch: 0.272s training loss: 0.3546, training accuracy: 0.8412\n",
      "[Epoch 0][Batch 781][Samples 25000] time/batch: 0.150s training loss: 0.3545, training accuracy: 0.8412\n",
      "[Epoch 0] Finished in 341.089s, training loss: 0.3545, training accuracy: 0.8412\n",
      "Train finished using total 341s with 1 epochs. training loss: 0.3545, training accuracy: 0.8412\n"
     ]
    }
   ],
   "source": [
    "trainer = mx.gluon.Trainer(net.collect_params(), 'bertadam',\n",
    "                        {'learning_rate': lr, 'wd':0.01})\n",
    "loss_fn = mx.gluon.loss.SoftmaxCELoss()\n",
    "metrics = [mx.metric.Loss(), mx.metric.Accuracy()]\n",
    "lr_handler = MyLearningRateHandler(trainer=trainer, num_warmup_steps=50, lr=5e-5,\n",
    "                                   num_train_steps = len(train_data) * num_epochs)\n",
    "logging_handler = LoggingHandler(train_metrics=metrics, verbose=LoggingHandler.LOG_PER_BATCH)\n",
    "event_handlers = [lr_handler, logging_handler]\n",
    "\n",
    "est = MyEstimator(net=net, loss=loss_fn, metrics=metrics, trainer=trainer, context=ctx)\n",
    "est.fit(train_data=train_data, epochs=num_epochs, event_handlers=event_handlers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(net, ctx, vocabulary, bert_tokenizer, sentence):\n",
    "    ctx = ctx[0] if isinstance(ctx, list) else ctx\n",
    "    max_len = 128\n",
    "    padding_id = vocabulary[vocabulary.padding_token]\n",
    "    \n",
    "    inputs = mx.nd.array([vocabulary[['[CLS]'] + bert_tokenizer(sentence) + ['SEP']]], ctx=ctx)\n",
    "    print(inputs)\n",
    "    seq_len = mx.nd.array([inputs.shape[1]], ctx=ctx)\n",
    "    token_types = mx.nd.zeros_like(inputs)\n",
    "    \n",
    "    out = net(inputs, token_types, seq_len)\n",
    "    label = mx.nd.argmax(out, axis=1)\n",
    "    return 'positive' if label.asscalar() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2.000e+00 2.023e+03 3.185e+03 2.003e+03 2.061e+03 2.307e+03 0.000e+00]]\n",
      "<NDArray 1x7 @gpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, ctx, vocabulary, tokenizer, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deploy on SageMaker\n",
    "\n",
    "1. Model parameters\n",
    "2. Code with data pre-processing and model inference\n",
    "3. A docker container with dependencies installed\n",
    "4. Launch a serving end-point with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### 1. Save Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# save parameters, model definition and vocabulary in a zip file\n",
    "net.export('checkpoint')\n",
    "with open('vocab.json', 'w') as f:\n",
    "    f.write(vocabulary.to_json())\n",
    "import tarfile\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"checkpoint-0000.params\") \n",
    "    tar.add(\"checkpoint-symbol.json\") \n",
    "    tar.add(\"vocab.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. the Code for Inference\n",
    "\n",
    "Two functions: \n",
    "1. model_fn() to load model parameters\n",
    "2. transform_fn() to run model inference given an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile serve.py\n",
    "import json, logging, warnings\n",
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the gluon model. Called once when hosting service starts.\n",
    "    :param: model_dir The directory where model files are stored.\n",
    "    :return: a Gluon model, and the vocabulary\n",
    "    \"\"\"\n",
    "    prefix = 'checkpoint'\n",
    "    net = mx.gluon.nn.SymbolBlock.imports(prefix + '-symbol.json',\n",
    "                                          ['data0', 'data1', 'data2'],\n",
    "                                          prefix + '-0000.params')\n",
    "    net.load_parameters('%s/' % model_dir + prefix + '-0000.params',\n",
    "                        ctx=mx.cpu())\n",
    "    vocab_json = open('%s/vocab.json' % model_dir).read()\n",
    "    vocab = nlp.Vocab.from_json(vocab_json)\n",
    "    tokenizer = nlp.data.BERTTokenizer(vocab)\n",
    "    return net, vocab, tokenizer\n",
    "\n",
    "\n",
    "def transform_fn(model, data, input_content_type, output_content_type):\n",
    "    \"\"\"\n",
    "    Transform a request using the Gluon model. Called once per request.\n",
    "    :param model: The Gluon model and the vocab\n",
    "    :param data: The request payload.\n",
    "    :param input_content_type: The request content type.\n",
    "    :param output_content_type: The (desired) response content type.\n",
    "    :return: response payload and content type.\n",
    "    \"\"\"\n",
    "    # we can use content types to vary input/output handling, but\n",
    "    # here we just assume json for both\n",
    "    net, vocabulary, tokenizer = model\n",
    "    sentence = json.loads(data)\n",
    "    result = predict_sentiment(net, mx.cpu(), vocabulary, tokenizer, sentence)\n",
    "    response_body = json.dumps(result)\n",
    "    return response_body, output_content_type\n",
    "\n",
    "\n",
    "def predict_sentiment(net, ctx, vocabulary, bert_tokenizer, sentence):\n",
    "    ctx = ctx[0] if isinstance(ctx, list) else ctx\n",
    "    max_len = 128\n",
    "    padding_id = vocabulary[vocabulary.padding_token]\n",
    "    \n",
    "    inputs = mx.nd.array([vocabulary[['[CLS]'] + bert_tokenizer(sentence) + ['SEP']]], ctx=ctx)\n",
    "    print(inputs)\n",
    "    seq_len = mx.nd.array([inputs.shape[1]], ctx=ctx)\n",
    "    token_types = mx.nd.zeros_like(inputs)\n",
    "    \n",
    "    out = net(inputs, token_types, seq_len)\n",
    "    label = mx.nd.argmax(out, axis=1)\n",
    "    return 'positive' if label.asscalar() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Build a Docker Container for Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's prepare a docker container with all the dependencies required for model inference. Here we build a docker container based on the SageMaker MXNet inference container, and you can find the list of all available inference containers at https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html\n",
    "\n",
    "Here we use local mode for demonstration purpose. To deploy on actual instances, you need to login into AWS elastic container registry (ECR) service, and push the container to ECR. \n",
    "\n",
    "```\n",
    "docker build -t $YOUR_EDR_DOCKER_TAG . -f Dockerfile\n",
    "$(aws ecr get-login --no-include-email --region $YOUR_REGION)\n",
    "docker push $YOUR_EDR_DOCKER_TAG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "ARG REGION\n",
    "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/mxnet-inference:1.4.1-gpu-py3\n",
    "\n",
    "RUN pip install --upgrade --user --pre 'mxnet-mkl' 'https://github.com/dmlc/gluon-nlp/tarball/v0.9.x'\n",
    "\n",
    "RUN pip list | grep mxnet\n",
    "\n",
    "COPY *.py /opt/ml/model/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  845.5MB\n",
      "Step 1/5 : ARG REGION\n",
      "Step 2/5 : FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/mxnet-inference:1.4.1-gpu-py3\n",
      "1.4.1-gpu-py3: Pulling from mxnet-inference\n",
      "\n",
      "\u001b[1Be2e5f967: Pulling fs layer \n",
      "\u001b[1B6638ac9f: Pulling fs layer \n",
      "\u001b[1B7d6d954b: Pulling fs layer \n",
      "\u001b[1Be5e2a643: Pulling fs layer \n",
      "\u001b[1B43379044: Pulling fs layer \n",
      "\u001b[1Bc12a6c3b: Pulling fs layer \n",
      "\u001b[1B93d9ac61: Pulling fs layer \n",
      "\u001b[1Bd383c253: Pulling fs layer \n",
      "\u001b[1B88e9cf77: Pulling fs layer \n",
      "\u001b[1B2c216fae: Pulling fs layer \n",
      "\u001b[1B57f9df51: Pulling fs layer \n",
      "\u001b[7Bc12a6c3b: Waiting fs layer \n",
      "\u001b[9B43379044: Waiting fs layer \n",
      "\u001b[6B88e9cf77: Waiting fs layer \n",
      "\u001b[1B50be1879: Pulling fs layer \n",
      "\u001b[1B39de1ac4: Pulling fs layer \n",
      "\u001b[1Bb57b569b: Pulling fs layer \n",
      "\u001b[1Bd0998084: Pulling fs layer \n",
      "\u001b[1B50407310: Pull complete  372B/372B2kBBK\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[KDownloading  136.7MB/599.8MB\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[KDownloading  167.3MB/599.8MB\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[KExtracting  68.52MB/244MB\u001b[5A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[KExtracting  549.3MB/599.8MB\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[KDigest: sha256:820360622386fc22ac0d8bcce84b2856b80a5df7e05a597931b2c76f779be920\n",
      "Status: Downloaded newer image for 763104351884.dkr.ecr.us-west-2.amazonaws.com/mxnet-inference:1.4.1-gpu-py3\n",
      " ---> d9dd4dcfe0c2\n",
      "Step 3/5 : RUN pip install --upgrade --user --pre 'mxnet-mkl' 'https://github.com/dmlc/gluon-nlp/tarball/v0.9.x'\n",
      " ---> Running in 4f41de41cf8b\n",
      "Collecting https://github.com/dmlc/gluon-nlp/tarball/v0.9.x\n",
      "  Downloading https://github.com/dmlc/gluon-nlp/tarball/v0.9.x\n",
      "Collecting mxnet-mkl\n",
      "  Downloading https://files.pythonhosted.org/packages/64/72/c5566aabde6ee0bda1f09d026603169a717dbd9f26f6be85ee2b4ed2cf03/mxnet_mkl-1.6.0b20191025-py2.py3-none-manylinux1_x86_64.whl (64.9MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/site-packages (from gluonnlp==0.9.0.dev0) (1.14.6)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/site-packages (from mxnet-mkl) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/site-packages (from mxnet-mkl) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (1.25.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (3.0.4)\n",
      "\u001b[91mERROR: mxnet-mkl 1.6.0b20191025 has requirement numpy<2.0.0,>1.16.0, but you'll have numpy 1.14.6 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: mxnet-mkl, gluonnlp\n",
      "  Running setup.py install for gluonnlp: started\n",
      "    Running setup.py install for gluonnlp: finished with status 'done'\n",
      "Successfully installed gluonnlp-0.9.0.dev0 mxnet-mkl-1.6.0b20191025\n",
      "\u001b[91mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 4f41de41cf8b\n",
      " ---> 5444665ccaaf\n",
      "Step 4/5 : RUN pip list | grep mxnet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---> Running in 0e4de03b4a12\n",
      "\u001b[91mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mkeras-mxnet                       2.2.4.1       \n",
      "mxnet-cu100mkl                    1.4.1         \n",
      "mxnet-mkl                         1.6.0b20191025\n",
      "mxnet-model-server                1.0.4         \n",
      "sagemaker-mxnet-serving-container 1.0.0         \n",
      "Removing intermediate container 0e4de03b4a12\n",
      " ---> 1b2f86ccfa5d\n",
      "Step 5/5 : COPY *.py /opt/ml/model/code/\n",
      " ---> 59af10505a04\n",
      "Successfully built 59af10505a04\n",
      "Successfully tagged my-docker:inference\n"
     ]
    }
   ],
   "source": [
    "!export REGION=$(wget -qO- http://169.254.169.254/latest/meta-data/placement/availability-zone) &&\\\n",
    " docker build --no-cache --build-arg REGION=${REGION::-1} -t my-docker:inference . -f Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use SageMaker SDK to Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We create a MXNet model which can be deployed later, by specifying the docker image, and entry point for the inference code. If serve.py does not work, use dummy_hosting_module.py for debugging purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet.model import MXNetModel\n",
    "sagemaker_model = MXNetModel(model_data='file:///home/ec2-user/SageMaker/reinvent19-gluonnlp/tutorial/model.tar.gz',\n",
    "                             image='my-docker:inference', # docker images\n",
    "                             role=sagemaker.get_execution_role(), \n",
    "                             py_version='py3',            # python version\n",
    "                             entry_point='serve.py',\n",
    "                             source_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We use 'local' mode to test our deployment code, where the inference happens on the current instance.\n",
    "If you are ready to deploy the model on a new instance, change the `instance_type` argument to values such as `ml.c4.xlarge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd47cfc6748>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd47cfc68d0>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd47db06390>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /ping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp8w7gb7gs_algo-1-5m4e3_1\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,025 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m MMS Home: /usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Current directory: /\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Temp directory: /home/model-server/tmp\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Number of GPUs: 0\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Number of CPUs: 8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Max heap size: 13646 M\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Python executable: /usr/local/bin/python3.6\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Management address: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Initial Models: ALL\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Log dir: /logs\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Netty threads: 0\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Netty client threads: 0\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Default workers per model: 8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,083 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,173 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,279 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,280 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]79\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,281 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,287 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,287 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,287 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,288 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,289 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]76\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,289 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,289 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,290 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,290 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,290 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]77\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,290 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,290 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,290 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,294 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]80\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,294 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,295 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,296 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,296 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]82\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,296 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,296 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,296 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,297 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,307 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,307 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]81\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,307 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,307 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,308 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,324 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,325 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]83\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,325 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,325 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,325 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,338 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,338 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]78\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,338 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,338 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,339 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,343 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,343 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Management server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,344 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9006.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,344 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9007.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,345 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9002.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,345 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9004.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,345 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9003.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,346 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,347 [INFO ] main com.amazonaws.ml.mms.ModelServer - Management API bind to: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,348 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9005.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m Model server started.\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:11,349 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,374 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3003\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,383 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3007\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,394 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3023\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,394 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3021\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,396 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3016\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,407 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3007\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,434 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3034\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:14,460 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3076\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:15,926 [INFO ] pool-1-thread-9 ACCESS_LOG - /172.18.0.1:57318 \"GET /ping HTTP/1.1\" 200 13\n",
      "!"
     ]
    }
   ],
   "source": [
    "# Here we use 'local' mode for testing, for real instances use c5.2xlarge, p2.xlarge, etc\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:15,971 [WARN ] W-9002-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - /root/.local/lib/python3.6/site-packages/mxnet/gluon/block.py:1366: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:15,971 [WARN ] W-9002-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - \tdata0: None\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:15,971 [WARN ] W-9002-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   input_sym_arg_type = in_param.infer_type()[0]\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:16,950 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - \n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:16,950 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [[2.000e+00 1.996e+03 2.944e+03 2.003e+03 7.333e+03 1.012e+03 2.307e+03\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:16,950 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   9.990e+02 0.000e+00]]\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:16,950 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - <NDArray 1x9 @cpu(0)>\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:17,079 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1132\n",
      "\u001b[36malgo-1-5m4e3_1  |\u001b[0m 2019-11-27 19:12:17,080 [INFO ] W-9002-model ACCESS_LOG - /172.18.0.1:57322 \"POST /invocations HTTP/1.1\" 200 1137\n",
      "\n",
      "Prediction output: positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = predictor.predict('The model is deployed. Great!')\n",
    "print('\\nPrediction output: {}\\n\\n'.format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clean Up\n",
    "\n",
    "Remove the endpoint after we are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Resources\n",
    "- Amazon SageMaker https://aws.amazon.com/sagemaker/\n",
    "- Amazon SageMaker Python SDK https://sagemaker.readthedocs.io/\n",
    "- GluonNLP http://gluon-nlp.mxnet.io/\n",
    "- GluonCV http://gluon-cv.mxnet.io/\n",
    "- GluonTS https://gluon-ts.mxnet.io/\n",
    "- Dive into Deep Learning http://d2l.ai/\n",
    "- MXNet Forum https://discuss.mxnet.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For more fine-tuning scripts, visit the [BERT model zoo webpage](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html).\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Devlin, Jacob, et al. \"Bert:\n",
    "Pre-training of deep\n",
    "bidirectional transformers for language understanding.\"\n",
    "arXiv preprint\n",
    "arXiv:1810.04805 (2018).\n",
    "\n",
    "[2] Dolan, William B., and Chris\n",
    "Brockett.\n",
    "\"Automatically constructing a corpus of sentential paraphrases.\"\n",
    "Proceedings of\n",
    "the Third International Workshop on Paraphrasing (IWP2005). 2005.\n",
    "\n",
    "[3] Peters,\n",
    "Matthew E., et al. \"Deep contextualized word representations.\" arXiv\n",
    "preprint\n",
    "arXiv:1802.05365 (2018).\n",
    "\n",
    "[4] Hendrycks, Dan, and Kevin Gimpel. \"Gaussian error linear units (gelus).\" arXiv preprint arXiv:1606.08415 (2016)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
